{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Bike Sharing Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.9.13\n",
      "Pandas Version: 2.0.2\n",
      "Matplotlib Version: 3.7.1\n",
      "Sklearn Version: 1.2.2\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Python Version:', python_version())\n",
    "\n",
    "# Verificando as versões dos pacotes instalados\n",
    "pandasVersion = !pip show pandas\n",
    "matplotlibVersion = !pip show matplotlib\n",
    "sklearnVersion = !pip show scikit-learn\n",
    "print('Pandas', pandasVersion[1])\n",
    "print(\"Matplotlib\", matplotlibVersion[1])\n",
    "print(\"Sklearn\", sklearnVersion[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Definição do Problema de Negócio\n",
    "<details>\n",
    "    <summary>\n",
    "        <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>&nbsp;&nbsp;Clique para mais detalhes</a>\n",
    "    </summary>\n",
    "    <br>\n",
    "\n",
    "Este conjunto de dados contém a contagem horária e diária de bicicletas alugadas entre os anos de 2011 e 2012 com as informações meteorológicas e sazonais correspondentes de um sistema de bicicletas compartilhadas. <br><br>\n",
    "Os sistemas de compartilhamento de bicicletas são uma nova geração de aluguel de bicicletas tradicionais, onde todo o processo de adesão, aluguel e devolução se tornou automático. Através desses sistemas, o usuário pode facilmente alugar uma bicicleta de um determinado local e devolver em outro. Existem cerca de 500 programas de compartilhamento de bicicletas em todo o mundo, totalizando mais de 500 mil bicicletas. Hoje, existe um grande interesse nestes sistemas devido ao seu importante papel nas questões de trânsito, ambientais e de saúde. <br><br>\n",
    "Além das aplicações interessantes oferecidas pelos sistemas de compartilhamento de bicicletas no mundo real, as características dos dados gerados por estes sistemas os tornam atraentes para pesquisas. Ao contrário de outros serviços de transporte, como ônibus ou metrô, a duração da viagem, o local de partida e chegada são registrados explicitamente nesses sistemas. Esse recurso transforma o sistema de compartilhamento de bicicletas em uma rede de sensores virtuais que pode ser usada para detectar a mobilidade na cidade. Assim, espera-se que a maioria dos eventos importantes na cidade possam ser detectados através do monitoramento desses dados. <br>\n",
    "    \n",
    "Descrição das variáveis:<br>\n",
    "- **instancia**: númerdo do registro;<br>\n",
    "- **data**: data do aluguel;<br>\n",
    "- **estacao**: estação do ano (1: inverno; 2: primavera; 3: verão; 4: outono); <br>\n",
    "- **ano**: ano (0: 2011; 1: 2012);<br> \n",
    "- **mes**: mês (1 a 12); <br>\n",
    "- **hora**: hora (0 a 23); <br>\n",
    "- **feriado**: indica se o dia é feriado ou não (0: não, 1: sim); <br>\n",
    "- **dia_da_semana**: dia da semana (0 a 6); <br>\n",
    "- **dia_de_trabalho**: se o dia não for fim de semana nem feriado, então é 1, caso contrário é 0; <br>\n",
    "- **condicao_tempo**: condição do tempo (1: Claro, Poucas nuvens, Parcialmente nublado; 2: Névoa + Nublado, Névoa + Nuvens quebradas, Névoa + Poucas nuvens, Névoa; 3: Neve fraca, Chuva fraca + Trovoada + Nuvens dispersas, Chuva fraca + Nuvens dispersas; 4: Chuva Pesada + Gelo + Trovoada + Névoa, Neve + Neblina); <br>\n",
    "- **temperatura**: temperatura em graus Celsius (normalizado); <br>\n",
    "- **sensacao_termica**: sensação térmica em graus Celsius (normalizado); <br>\n",
    "- **umidade**: umidade relativa do ar (máximo de 100), normalizado;<br>\n",
    "- **veloc_vento**: velocidade do vento (máximo de 67), normalizado; <br>\n",
    "- **casual**: contagem de usuários casuais; <br>\n",
    "- **registrado**: contagem de usuários registrados; <br>\n",
    "- **contagem**: (variável alvo) quantidade total de bicicletas alugadas, incluindo usuários casuais e registrados. <br>\n",
    "\n",
    "Bike Sharing Dataset possui dois arquivos:<br>\n",
    "- **hour.csv**: contém a quantidade de bicicletas alugadas por hora. Registros: 17379 horas; <br>\n",
    "- **day.csv**: possui a quantidade de bicicletas alugadas por dia. Registros: 731 dias;<br>\n",
    "\n",
    "Obs.: Trabalharemos com o arquivo hour.csv\n",
    "\n",
    "Endereço do conjunto de dados: https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 - Coletando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação e exploração do conjunto de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cálculos matemáticos\n",
    "import math\n",
    "\n",
    "# Plotagem de gráficos\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imputação de valores nulos\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Converter variáveis categóricas em números\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Seleção de variáveis\n",
    "from sklearn.feature_selection import RFE, SelectKBest\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Dividir dados de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Buscar os melhores parâmetros que serão utilizados nos modelos preditivos\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Algoritmos de Regressão\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor, AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Métricas de avaliação dos modelos preditivos\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Carregar e salvar objetos Python em arquivos no disco\n",
    "import pickle\n",
    "\n",
    "# Esse módulo ignara os avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 - Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando os dados \n",
    "df = pd.read_csv('Dados/Bike-Sharing/hour.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando as colunas\n",
    "colunas = ['instancia', 'data', 'estacao', 'ano', 'mes', 'hora', 'feriado', 'dia_da_semana', 'dia_de_trabalho', 'condicao_tempo', 'temperatura', 'sensacao_termica', 'umidade', \n",
    "           'veloc_vento', 'casual', \"registrado\", 'contagem']\n",
    "df.columns = colunas\n",
    "\n",
    "# Separando a variável alvo\n",
    "variavelAlvo = \"contagem\"\n",
    "\n",
    "# Visualizando primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo colunas desnecessárias\n",
    "df.drop(['instancia', 'data'], axis=1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Reservar linhas para validar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma amostra do conjuto de dados\n",
    "# O parâmetro \"n\" define a quantidade de linhas da amostra\n",
    "dfValidacao = df.sample(n=2, random_state=1)\n",
    "dfValidacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo do DataFrame original as linhas que serão utilizadas para validar o modelo \n",
    "for k in dfValidacao.index:\n",
    "    df.drop([k], inplace = True)\n",
    "\n",
    "# É importante reiniciar os índices após a exclusão de linhas\n",
    "df.reset_index(inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo coluna\n",
    "df.drop([\"index\"], axis=1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Explorando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 - Informações sobre o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando informações sobre o dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo variáveis do tipo inteiro ou float para o tipo categórica\n",
    "df.estacao = df.estacao.astype(\"category\")\n",
    "df.ano = df.ano.astype(\"category\")\n",
    "df.mes = df.mes.astype(\"category\")\n",
    "df.hora = df.hora.astype(\"category\")\n",
    "df.feriado = df.feriado.astype(\"category\")\n",
    "df.dia_da_semana = df.dia_da_semana.astype(\"category\")\n",
    "df.dia_de_trabalho = df.dia_de_trabalho.astype(\"category\")\n",
    "df.condicao_tempo = df.condicao_tempo.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Tratando valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores nulos por coluna\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 - Tratando dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem dados duplicados.\n",
    "# Ocorrem dados duplicados quando uma linha inteira é igual a outra\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo as linhas duplicadas mantendo a primeira ocorrência da linha\n",
    "df.drop_duplicates(ignore_index=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 - Tratando valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores únicos\n",
    "# Variáveis quantitativas com muitos valores únicos podem prejudicar o aprendizado de máquina\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 - Análise descritiva dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.1 - Parâmetros dos gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a paleta de cores\n",
    "sns.color_palette(\"pastel\")\n",
    "\n",
    "# Define o tema utilizado.\n",
    "sns.set_theme(style=\"darkgrid\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.2 - Funções para desenhar os gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### a) Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um histograma\n",
    "def desenhaHistograma(coluna, variavelAnalisada):\n",
    "\n",
    "    # Calculando a quantidade de classes da variável analisada\n",
    "    n = coluna.count()\n",
    "    k = round(1+3.3*math.log10(n))\n",
    "   \n",
    "    # Calculando o intervalo de cada classe\n",
    "    frequencias, intervalos = np.histogram(coluna, bins = k)\n",
    "\n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.histplot(coluna, bins=k, kde=True)\n",
    "    ax.set_title(\"Histograma da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.set_xlabel(variavelAnalisada, fontsize = 12)\n",
    "    ax.set_ylabel(\"Frequência\", fontsize = 12)\n",
    "    ax.set_xticks(intervalos) \n",
    "    for barras in ax.containers:\n",
    "        ax.bar_label(barras)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b) Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um Boxplot\n",
    "def desenhaBoxplot(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.boxplot(data=coluna)\n",
    "    ax.set_title(\"Boxplot da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.set_xticklabels([variavelAnalisada]) # exibe o nome da variável\n",
    "    larguraBox = 0.63\n",
    "    i=0\n",
    "\n",
    "    # calcula o primeiro quartil (q1), o segundo (q2) e o terceiro quartil (q3)\n",
    "    q1, q2, q3 = coluna.quantile(0.25), coluna.quantile(0.5), coluna.quantile(0.75)\n",
    "    \n",
    "    # Lista com os quartis\n",
    "    quartis = [q1, q2, q3]\n",
    "\n",
    "    # Exibe os quartis no gráfico\n",
    "    for q in quartis:\n",
    "        x = i-larguraBox/2\n",
    "        y = q\n",
    "        ax.annotate('%.2f' % q, (x,y),\n",
    "                    xytext=(x-0.1, y), textcoords='data',\n",
    "                    va='center', ha='right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### c) Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um Scatter Plot\n",
    "def desenhaScatterPlot(colunaX, colunaY, variavelAnalisadaX, variavelAnalisadaY):\n",
    "    \n",
    "    # Cria o gráfico definido pelos valores do eixo x e do eixo y respectivamente.\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.scatterplot(x=colunaX, y=colunaY) \n",
    "    ax.set_title(\"Relação da variável \" + variavelAnalisadaX + \" com a variável \" + variavelAnalisadaY, fontsize = 16)\n",
    "    ax.set_xlabel(variavelAnalisadaX, fontsize = 12)\n",
    "    ax.set_ylabel(variavelAnalisadaY, fontsize = 12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### d) Gráfico de Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um gráfico de pizza\n",
    "def desenhaPizza(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Calculando o percentual\n",
    "    percentuais = round((coluna.value_counts()/coluna.value_counts().sum())*100, 2)\n",
    "\n",
    "    # Nome das categorias\n",
    "    nomeDasCategorias = coluna.value_counts().index\n",
    "\n",
    "    # Desenhando o gráfico\n",
    "    fig, ax = plt.subplots(figsize=(13, 6))\n",
    "    ax.pie(percentuais, labels=nomeDasCategorias, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    ax.set_title(\"Percentuais da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.legend(title=variavelAnalisada,loc=\"center left\",bbox_to_anchor=(1., 0., 0.5, 1.))\n",
    "    ax.axis('equal') # Garante que o gráfico seja desenhado no formato de círculo.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### d) Countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um gráfico Countplot\n",
    "def desenhaCountPlot(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.countplot(x=coluna, palette=(\"Pastel1\"), order = coluna.value_counts().index)\n",
    "    ax.set_title(\"Frequência absoluta da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    for barras in ax.containers:\n",
    "        ax.bar_label(barras)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### e) Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um gráfico da média da variável alvo de acordo com uma determinada variável\n",
    "def desenhaBarplotMedia(variavelAnalisada):\n",
    "    ax = df.groupby(variavelAnalisada)[variavelAlvo].agg([\"mean\"]).sort_values(by=[\"mean\"], ascending=False).plot.bar(figsize=(13, 6))\n",
    "    plt.title(\"Média da variável alvo de acordo com a coluna \" + variavelAnalisada, fontsize = 16)\n",
    "    plt.xticks(rotation=0)\n",
    "    ax.set_ylabel(\"Média\", fontsize = 12)\n",
    "    plt.legend('', frameon=False)#remove a legenda\n",
    "    for barras in ax.containers:\n",
    "        ax.bar_label(barras)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.3 Análise descritiva das variáveis quantitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "for k in df.columns[0:14]:\n",
    "    # Verifica se a coluna não possui valores do tipo categórico\n",
    "    if df[k].dtype.name != \"category\":\n",
    "        \n",
    "        # Sumário estatístico\n",
    "        print(\"Resumo estatístico da variável \" + k + \"\\n\", df[k].describe())\n",
    "        \n",
    "        # Histograma\n",
    "        desenhaHistograma(df[k], k)\n",
    "        \n",
    "        # Boxplot\n",
    "        desenhaBoxplot(df[k], k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.4 Análise descritiva das variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "for k in df.columns[0:14]:\n",
    "    # Verifica se a coluna é do tipo category\n",
    "    if df[k].dtype.name == \"category\":\n",
    "        \n",
    "        # Frequência absoluta \n",
    "        desenhaCountPlot(df[k], k)\n",
    "        \n",
    "        # Percentuais\n",
    "        desenhaPizza(df[k], k)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.5 Análise descritiva da variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "pd.DataFrame(df[variavelAlvo].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequência absoluta \n",
    "desenhaHistograma(df[variavelAlvo], variavelAlvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentuais\n",
    "desenhaBoxplot(df[variavelAlvo], variavelAlvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.6 - Correlação entre as variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.5.6.1 - Matriz de correlação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a correlação \n",
    "correlacao = df.corr()\n",
    "\n",
    "# Criando uma máscara\n",
    "mascara = np.zeros_like(correlacao)\n",
    "\n",
    "# Selecionando a matriz triangular inferior da máscara.\n",
    "mascara[np.triu_indices_from(mascara)] = True\n",
    "\n",
    "# Desenhando o gráfico\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "sns.heatmap(data = correlacao,\n",
    "            mask = mascara,\n",
    "            annot = True,\n",
    "            fmt = '.2f',\n",
    "            cmap='Blues',\n",
    "\n",
    "            )\n",
    "plt.title('Matriz de correlação', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.5.6.2 - Correlação entre a variável Casual e a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScatterPlot\n",
    "desenhaScatterPlot(df.casual, df.contagem, \"casual\",\"contagem\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.5.6.3 - Correlação entre a variável Registrado e a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScatterPlot\n",
    "desenhaScatterPlot(df.registrado, df.contagem, \"registrado\",\"contagem\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.5.6.4 - Analisar os dados de acordo com a variável variavel alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### a) Analisando as variáveis quantitativas de acordo com a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico com a média de aluguéis de bicicletas de acordo com a temperatura\n",
    "ax = df.groupby(\"temperatura\")[variavelAlvo].agg([\"mean\"]).sort_values(by=[\"temperatura\"], ascending=False).plot.barh(figsize=(13, 13))\n",
    "plt.title(\"Média de aluguéis de bicicletas de acordo com a temperatura\", fontsize = 16)\n",
    "plt.xticks(rotation=0)\n",
    "ax.set_ylabel(\"Temperatura\", fontsize = 12)\n",
    "ax.set_xlabel(\"Aluguéis de bicicletas\", fontsize = 12)\n",
    "plt.legend('', frameon=False) # remove a legenda\n",
    "for barras in ax.containers:\n",
    "    ax.bar_label(barras)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico com a média de aluguéis de bicicletas de acordo com a umidade\n",
    "ax = df.groupby(\"umidade\")[variavelAlvo].agg([\"mean\"]).sort_values(by=[\"umidade\"], ascending=False).plot.barh(figsize=(16, 13))\n",
    "plt.title(\"Média de aluguéis de bicicletas de acordo com a umidade\", fontsize = 16)\n",
    "plt.xticks(rotation=0)\n",
    "ax.set_ylabel(\"Umidade\", fontsize = 12)\n",
    "ax.set_xlabel(\"Aluguéis de bicicletas\", fontsize = 12)\n",
    "plt.legend('', frameon=False) # remove a legenda\n",
    "for barras in ax.containers:\n",
    "    ax.bar_label(barras)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### a) Analisando as variáveis categóricas de acordo com a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "for k in df.columns:\n",
    "    # Verifica se a coluna é do tipo category\n",
    "    if df[k].dtype.name == \"category\":\n",
    "        # Desenha um barplot com a védia da variável alvo conforme a coluna\n",
    "        desenhaBarplotMedia(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Transformando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz uma cópia do dataframe\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Tratando valores iguais a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as colunas que possuem valores iguais a zero\n",
    "# Loop que percorre todas as colunas\n",
    "# A notação de slicing [0:13] é para não incluir a variável alvo, porque apesar de ter números, a variável alvo é categórica\n",
    "for k in df2.columns[0:13]:\n",
    "    \n",
    "    # Verifica se os valores não são do tipo texto\n",
    "    if df[k].dtype.name == \"category\":\n",
    "        \n",
    "        # Imprime na tela a quantidade de valores iguais a zero existentes na coluna\n",
    "        print(k + \":\", len(df2[df2[k] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Identificando e tratando valores outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "# A notação de slicing [0:14] é para não incluir a variável alvo, porque apesar de ter números, a variável alvo é categórica\n",
    "for k in df2.columns[0:14]:\n",
    "    \n",
    "    # Verifica se os valores da coluna não são do tipo texto\n",
    "    if df[k].dtype.name != \"category\":\n",
    "       \n",
    "        # Calculando o zscore da coluna\n",
    "        zscore = (df2[k] - df2[k].mean()) / df2[k].std()\n",
    "        \n",
    "        # Pesquisando valores menores que -3 ou maiores que 3 que são considerados outliers\n",
    "        outliers = zscore[(zscore < -3) | (zscore > 3)]\n",
    "        \n",
    "        # Calculando o limite superior\n",
    "        limiteSuperior = df2[k].mean() + 3 * df2[k].std()\n",
    "\n",
    "        # Calculando o limite inferior\n",
    "        limiteInferior = df2[k].mean() - 3 * df2[k].std()\n",
    "        \n",
    "        # Verifica se há outliers na coluna \n",
    "        if len(outliers) > 0:\n",
    "            \n",
    "            # Calcula a média da coluna, excluindo os valores outliers\n",
    "            media = df2[k][(df[k] > limiteInferior) & (df2[k] <= limiteSuperior)].mean()\n",
    "            \n",
    "            # Cria uma lista vazia para armazenar as linhas com outliers\n",
    "            linhasComOutlier = []\n",
    "             \n",
    "            # Loop que percorre as linhas com outliers\n",
    "            for j in outliers.index:\n",
    "                \n",
    "                # Substitui a célula com valor outlier pela média\n",
    "                df2[k] = df2[k].replace(df2.iloc[j][k], media)\n",
    "                \n",
    "                # Adiciona o índice da linha na lista\n",
    "                linhasComOutlier.append(j)\n",
    "                \n",
    "            print(\"- Quantidade de valores outliers \" + \"da variável \" + k + \" substituídos pela média\"  + \":\", len(outliers))\n",
    "            print(\"- Linha (as) da variável \" + k + \" que foi (foram) alterada (as):\", linhasComOutlier)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Convertendo variáveis categóricas em números"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Convertendo as variáveis preditoras de texto para número"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2.1 Encoding com o Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3 = pd.get_dummies(df2)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizando o nome das colunas\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Organizando o dataframe\n",
    "valoresVariavelAlvo = df3[variavelAlvo]\n",
    "df3.drop([variavelAlvo],  axis=1, inplace = True)\n",
    "\n",
    "# Atualizando a variável alvo\n",
    "df3[variavelAlvo] = valoresVariavelAlvo\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Dividindo os dados em treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATENÇÃO!! Qual o dataframe será utilizado df2 ou df3 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo uma cópia do dataframe\n",
    "dfDados = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(dfDados)\n",
    "numeroVariaveisPreditoras = len(dfDados.columns)-1\n",
    "\n",
    "# A notação de slicing [0:14] é para não incluir a variável alvo\n",
    "X = dfDados[dfDados.columns[0:14]].values.reshape((numeroObservacoes, numeroVariaveisPreditoras)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = dfDados[variavelAlvo].values # y pode ser um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisa os melhores valores para o parâmetro random_state\n",
    "# Array de valores para random_state de 1 até 200\n",
    "arrayRandomStates = np.arange(start=1, stop=200)\n",
    "\n",
    "# Cria uma lista vazia para armazenar os acertos\n",
    "listaR2 = []\n",
    "\n",
    "# Loop que percorre todos os valores da arrayRandomStates\n",
    "for k in arrayRandomStates:\n",
    "    Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=k)\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(Xtreino, Ytreino)\n",
    "    previsoes = modelo.predict(Xteste)\n",
    "    listaR2.append(round(r2_score(Yteste, previsoes)*100,2))\n",
    "    \n",
    "# Exibe os melhores valores para o random_state\n",
    "resultados = pd.DataFrame({'random_state':arrayRandomStates, \n",
    "                           'R2':listaR2})\n",
    "melhorRandomState = resultados[resultados['R2'] == resultados['R2'].max()]\n",
    "melhorRandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide os dados em treino e teste\n",
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=int(melhorRandomState[\"random_state\"][0:1].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Seleção de variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - Selecionado as melhores variáveis com o Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "randomForestRegressor = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Treinando o modelo\n",
    "randomForestRegressor.fit(X, y)\n",
    "\n",
    "# Atribuindo a importância das variáveis a uma Series do Pandas\n",
    "importanciaVariaveis = pd.Series(data = randomForestRegressor.feature_importances_, index = dfDados.columns[0:14])\n",
    "\n",
    "# Gráfico com a importância das variáveis\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "importanciaVariaveis.sort_values().plot.bar()\n",
    "plt.title(\"Importância das variáveis - Random Forest\", fontsize = 16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 - Selecionado as melhores variáveis com o SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria o objeto SelectKBest\n",
    "selectkBest = SelectKBest(k = 4)\n",
    "\n",
    "# Executa a função em (X, y) e obtém as variáveis selecionadas\n",
    "selectkBestTreinado = selectkBest.fit(X, y)\n",
    "\n",
    "# Atribuindo a importância das variáveis a uma Series do Pandas\n",
    "importanciaVariaveis = pd.Series(data = selectkBestTreinado.scores_, index = dfDados.columns[0:14])\n",
    "\n",
    "# Gráfico com a importância das variáveis\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "importanciaVariaveis.sort_values().plot.bar()\n",
    "plt.title(\"Importância das variáveis - SelectKBest\", fontsize = 16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 - Selecionado as melhores variáveis com Eliminação Recursiva de Atributos RFE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "extraTreesRegressor = ExtraTreesRegressor(random_state=0)\n",
    "\n",
    "# Treinando o modelo\n",
    "extraTreesRegressor.fit(X, y)\n",
    "\n",
    "# Criando Eliminação Recursiva de Atributos RFE\n",
    "eliminacaoRecursiva = RFE(extraTreesRegressor)\n",
    "\n",
    "# Treinando Eliminação Recursiva de Atributos RFE\n",
    "eliminacaoRecursivaTreinada = eliminacaoRecursiva.fit(X, y)\n",
    "\n",
    "# Gráfico com a importância das variáveis\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "plt.title(\"Importância das variáveis - RFE\", fontsize = 16)\n",
    "plt.bar(dfDados.columns[0:14], eliminacaoRecursivaTreinada.support_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Dividindo os dados de treino e teste com as variáveis selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variáveis selecionadas\n",
    "variaveisSelecionadas = [\"INDUS\", \"RM\", \"DIS\", \"TAX\", \"PTRATIO\", \"LSTAT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(dfDados)\n",
    "numeroVariaveisPreditoras = len(variaveisSelecionadas)\n",
    "X = dfDados[variaveisSelecionadas].values.reshape((numeroObservacoes, numeroVariaveisPreditoras)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = dfDados[variavelAlvo].values # y pode ser um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pesquisa os melhores valores para o parâmetro random_state\n",
    "# Array de valores para random_state de 1 até 100\n",
    "arrayRandomStates = np.arange(start=1, stop=200)\n",
    "\n",
    "# Cria uma lista vazia para armazenar os acertos\n",
    "listaR2 = []\n",
    "\n",
    "# Loop que percorre todos os valores da arrayRandomStates\n",
    "for k in arrayRandomStates:\n",
    "    Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=k)\n",
    "    modelo = XGBRegressor()\n",
    "    modelo.fit(Xtreino, Ytreino)\n",
    "    previsoes = modelo.predict(Xteste)\n",
    "    listaR2.append(round(r2_score(Yteste, previsoes)*100,2))\n",
    "    \n",
    "# Exibe os melhores valores para o random_state\n",
    "resultados = pd.DataFrame({'random_state':arrayRandomStates, \n",
    "                           'R2':listaR2})\n",
    "melhorRandomState = resultados[resultados['R2'] == resultados['R2'].max()]\n",
    "melhorRandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Divide os dados em treino e teste\n",
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=int(melhorRandomState[\"random_state\"][0:1].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaCrossValidation(dadosEntrada, dadosSaida):\n",
    "    # Criando uma lista vazia para armazenar os modelos de Machine Learning\n",
    "    modelos = []\n",
    "    \n",
    "    # Adicionando os modelos a lista\n",
    "    modelos.append((\"Regressão Linear\", LinearRegression()))\n",
    "    modelos.append((\"Ridge\", Ridge()))\n",
    "    modelos.append((\"KNN\", KNeighborsRegressor()))\n",
    "    modelos.append((\"SVM\", LinearSVR()))\n",
    "    modelos.append((\"Árvore de Decisão\", DecisionTreeRegressor()))\n",
    "    modelos.append((\"Random Forest\", RandomForestRegressor()))\n",
    "    modelos.append((\"Extra Tree\", ExtraTreesRegressor()))\n",
    "    modelos.append((\"Bagging\", BaggingRegressor()))\n",
    "    modelos.append((\"AdaBoost\", AdaBoostRegressor()))\n",
    "    modelos.append((\"Voting\", VotingRegressor(estimators=[(\"AD\",DecisionTreeRegressor()),(\"GB\", GradientBoostingRegressor()),(\"RL\", LinearRegression())])))\n",
    "    modelos.append((\"Gradient Tree Boosting\", GradientBoostingRegressor()))\n",
    "    modelos.append((\"XGBoost\", XGBRegressor()))    \n",
    "\n",
    "    # Criando um Dataframe para armazenar a média de cada um dos algoritmos testados.\n",
    "    dfMedias   = pd.DataFrame(columns = ['Algoritmo', 'Media'])\n",
    "\n",
    "    # Define a quantidade de folds\n",
    "    numeroFolds = 5\n",
    "\n",
    "    # Define a semente para criar os folds\n",
    "    seed = 28\n",
    "\n",
    "    # KFold divide o conjunto de dados em grupos de amostras, chamados folds\n",
    "    kfold = KFold(n_splits = numeroFolds, shuffle=True, random_state = seed)\n",
    "\n",
    "    for nome, construtor in modelos:\n",
    "        # Cross Validation\n",
    "        resultados = cross_val_score(construtor, dadosEntrada, dadosSaida, cv=kfold, scoring=\"r2\")\n",
    "\n",
    "        # Calcula a média dos resultados\n",
    "        media = resultados.mean()*100\n",
    "\n",
    "        # Define os parâmetros para adicionar a linha no dataframe\n",
    "        novaLinha = {\"Algoritmo\": nome,\n",
    "                     \"Media\": media}\n",
    "\n",
    "        # Adicionando uma linha no final do DataFrame\n",
    "        dfMedias.loc[len(dfMedias.index)] = novaLinha\n",
    "\n",
    "    # Ordena o dataframe da maior média para a menor    \n",
    "    dfMedias.sort_values(by=[\"Media\"], ascending=False, inplace=True)\n",
    "    \n",
    "    return dfMedias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 - Cross Validation com dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 - Cross Validation com dados normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria o objeto da classe MinMaxScaler \n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de entrada\n",
    "xNormalizado = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(xNormalizado, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 - Cross Validation com dados padronizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria o objeto StandardScaler, calcula a média e o desvio-padrão que serão usados para padronizar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de entrada\n",
    "xPadronizado = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(xPadronizado, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Preparando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 - Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria o objeto da classe MinMaxScaler \n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de  Xtreino\n",
    "XtreinoNormalizados = min_max_scaler.fit_transform(Xtreino)\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de Xteste\n",
    "XtesteNormalizados = min_max_scaler.fit_transform(Xteste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 - Padronizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria o objeto StandardScaler, calcula a média e o desvio-padrão que serão usados para padronizar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de Xtreino\n",
    "XtreinoPadronizados = scaler.fit_transform(Xtreino)\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de Xteste\n",
    "XtestePadronizados = scaler.fit_transform(Xteste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 - Selecionando a apresentação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Os dados podem estar com apresentação \"Originais\", \"Normalizados\" ou \"Padronizados\"\n",
    "apresentacaoDosDados = \"Originais\"\n",
    "\n",
    "if apresentacaoDosDados == \"Originais\":\n",
    "    dadosXtreino = Xtreino\n",
    "    dadosXteste = Xteste\n",
    "elif apresentacaoDosDados == \"Normalizados\":\n",
    "    dadosXtreino = XtreinoNormalizados\n",
    "    dadosXteste = XtesteNormalizados\n",
    "else:\n",
    "    dadosXtreino = XtreinoPadronizados\n",
    "    dadosXteste = XtestePadronizados\n",
    "\n",
    "print(\"Os dados estão com a seguinte apresentação:\", apresentacaoDosDados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Criando os modelos de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame para comparar a acurácia de cada algoritmo\n",
    "# DataFrame para comparar a R2 de cada algoritmo\n",
    "comparaAlgoritmo = {\"Algoritmo\": [\"Regressão Linear\", \"Ridge\", \"SVM\"],\n",
    "                   \"R2\": [\"-\", \"-\", \"-\"],\n",
    "                   \"Erro Absoluto Medio\": [\"-\", \"-\", \"-\"]\n",
    "                   }\n",
    "dfComparaAlgoritmo = pd.DataFrame(comparaAlgoritmo)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 - Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "linearRegression = LinearRegression()\n",
    "\n",
    "# Treinamento do modelo\n",
    "linearRegression.fit(Xtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = linearRegression.predict(Xteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Erro Absoluto Médio\n",
    "mae = mean_absolute_error(Yteste, previsoes)\n",
    "print(\"Erro absoluto médio: %.2f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[0,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[0,2] =  round(mae,2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "ridge = Ridge()\n",
    "\n",
    "# Treinamento do modelo\n",
    "ridge.fit(Xtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = ridge.predict(Xteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Erro Absoluto Médio\n",
    "mae = mean_absolute_error(Yteste, previsoes)\n",
    "print(\"Erro absoluto médio: %.2f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[1,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[1,2] =  round(mae, 2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "linearSvr = LinearSVR()\n",
    "\n",
    "# Treinamento do modelo\n",
    "linearSvr.fit(Xtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = linearSvr.predict(Xteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Erro Absoluto Médio\n",
    "mae = mean_absolute_error(Yteste, previsoes)\n",
    "print(\"Erro absoluto médio: %.2f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[2,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[2,2] =  round(mae, 2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - Selecionando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena o DataFrame de acordo o valor do Erro Absoluto Medio, em ordem crecente\n",
    "dfComparaAlgoritmo.sort_values(by=[\"Erro Absoluto Medio\"], inplace=True)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o modelo final\n",
    "modeloFinal = linearRegression\n",
    "modeloFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 - Salvando e carregando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 - Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo\n",
    "arquivo = 'Dados/Bike-Sharing/modeloRegresorFinal.sav'\n",
    "pickle.dump(modeloFinal, open(arquivo, 'wb'))\n",
    "print(\"Modelo salvo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 - Carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo\n",
    "modeloRegresor = pickle.load(open(arquivo, 'rb'))\n",
    "print(\"Modelo carregado!\")\n",
    "modeloRegresor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 - Salvando o objeto de normalização/padronização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os dados podem estar com apresentação \"Originais\", \"Normalizados\" ou \"Padronizados\"\n",
    "if apresentacaoDosDados == \"Normalizados\":\n",
    "    arquivoNormalizador = 'Dados/Bike-Sharing/normalizador.sav'\n",
    "    pickle.dump(min_max_scaler, open(arquivoNormalizador, 'wb'))\n",
    "    print(\"Normalizador salvo!\")\n",
    "elif apresentacaoDosDados == \"Padronizados\":\n",
    "    arquivoPadronizador = 'Dados/Bike-Sharing/padronizador.sav'\n",
    "    pickle.dump(scaler, open(arquivoPadronizador, 'wb'))\n",
    "    print(\"Padronizador salvo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 - Validando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o dataframe\n",
    "dfValidacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz as previsões dos novos dados\n",
    "\n",
    "if apresentacaoDosDados == \"Originais\":\n",
    "    novosDados = dfValidacao[dfValidacao.columns[0:14]].values\n",
    "    # Fazendo previsões\n",
    "    previsoes = modeloRegresor.predict(novosDados)\n",
    "\n",
    "elif apresentacaoDosDados == \"Normalizados\":\n",
    "    # Carregando o objeto de normalização dos dados\n",
    "    normalizador = pickle.load(open(arquivoNormalizador, 'rb'))\n",
    "    # Normalizando os novos dados\n",
    "    novosDados = dfValidacao[df.columns[0:14]].values\n",
    "    novosDadosNormalizados = normalizador.transform(novosDados)\n",
    "    previsoes = modeloRegresor.predict(novosDadosNormalizados)\n",
    "\n",
    "else:\n",
    "    # Carregando o objeto de padronização dos dados\n",
    "    padronizador = pickle.load(open(arquivoPadronizador, 'rb'))\n",
    "    # Padronizando os novos dados\n",
    "    novosDados = dfValidacao[df.columns[0:14]].values\n",
    "    novosDadosPadronizados = padronizador.transform(novosDados)\n",
    "    # Fazendo previsões\n",
    "    previsoes = modeloRegresor.predict(novosDadosPadronizados)\n",
    "\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
