{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7abf1219abb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Carregando Bibliotecas Python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Etapa 1 - Coletando os dados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observações\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "Também conhecido como Data Mungig, ETL, Manipulação de Dados, Data Wrangling <br>\n",
    "O processo é cíclico. Ou seja, deve-se voltar ao início após o processamento dos dados.<br>\n",
    "É sempre importante salvar os dados antes das transformações para comparações futuras. <br>\n",
    "Perguntas:<br>\n",
    "Os dados representam a população ou uma amostra?<br>\n",
    "A fonte dos dados é primária ou secundária?<br>\n",
    "Existem diversas considerações ao se carregar dados para o processo de Machine Learning. Por exemplo: seus dados possuem um header (cabeçalho)? Caso negativo, você vai precisar definir o título para cada coluna. Seus arquivos possuem comentários? Qual o delimitador das colunas? Alguns dados estão entre aspas, simples ou duplas?    \n",
    "\n",
    "Link com os datasets do scikit learn\n",
    "https://scikit-learn.org/stable/datasets/toy_dataset.html\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura de arquivo CSV\n",
    "# ficar atento ao separador de colunas (atributo \"sep\") pode ser \";\", \",\" \"|\"\n",
    "dados = pd.read_csv('dados\\pima-data.csv', sep = ',', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura de arquivo EXCELL\n",
    "dados = pd.read_excel(\"dados\\df_2020.xlsx\", sheet_name=\"nome da planilha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando um dataset Iris que já vem com o Seaborn\n",
    "dados = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Etapa 2: Explorando e Preparando os Dados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observações\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "Também conhecido como Data Mungig, ETL, Manipulação de Dados, Data Wrangling \n",
    "O processo é cíclico. Ou seja, deve-se voltar ao início após o processamento dos dados.\n",
    "É sempre importante salvar os dados antes das transformações para comparações futuras.\n",
    "Perguntas:\n",
    "Os dados representam a população ou uma amostra?\n",
    "A fonte dos dados é primária ou secundária?\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualizando os dados\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualizando algumas linhas. O atributo \"n\" define a quantidade de linhas\n",
    "#dados.head()\n",
    "dados.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Verificar se as variáveis estão nas colunas e se os registros estão nas linhas\n",
    "# As variáveis devem ficar nas colunas e devem conter apenas uma informação\n",
    "#   1 - Converter linha em coluna: \n",
    "dados.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar os tipos de variáveis:\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "    # Separar variáveis categóricas de variáveis numéricas. É bom criar gráficos e analisá-las separadamente. <br>\n",
    "1 - qualitativas/categóricas: <br>\n",
    "    a) nominais -  Não existe uma ordem implícita (Ex.: sexo, religião, profissão) <br>\n",
    "    b) ordinais - Possuem uma ordem natural (Ex.: Escolaridade, classe social)<br>\n",
    "2 - quantitativas: <br>\n",
    "    a) discretas - pode ser obtida através de uma contagem simples (idade, ano, quantidade) <br>\n",
    "    b) contínuas - precisa de um processo para ser obtida (peso, altura, tamanho) - representadas por valores decimais <br> \n",
    "    Verificar se existe duplicação nas linhas e colunas <br>\n",
    "    Verificar se as variáveis numéricas possuem muitos valores únicos. Caso isso aconteça, talvez seja interessante converter essa variável para categórica.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualizar qual o tipo de dado a variável foi classificada no momento da leitura do arquivo \n",
    "dados.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Exibir resumo do data set\n",
    "dados.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Verificar se as classes estão com divisão balanceada, ou seja, com a mesma quantidade para cada classe.\n",
    "# fazer a mesma verificação nos dados de treino. Oversampling aumenta a quantidade da classe com menor quantidade (SMOTE). Undersampling diminui a quantidade da classe com maior quantidade. \n",
    "# A técnica SMOTE cria novas linhas baseado nas distâncias matemáticas dos atributos dos registros de uma determinada classe.\n",
    "# Aplicar o balanceamento de classes somente aos dados de treino.\n",
    "# Quantitativo da variável alvo \n",
    "dados[\"species\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Instala e importa o pacote imblearn que contem o SMOTE\n",
    "!pip install -q imblearn\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Shape\n",
    "df_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Variáveis explicativas\n",
    "df_original.iloc[:, 0:17].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Variável Target\n",
    "df_original.iloc[:, 17].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanceamento de Classe - Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Importa a função\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Seed para reproduzir o mesmo resultado\n",
    "seed = 100\n",
    "\n",
    "# Separa X e y\n",
    "X = df_original.iloc[:, 0:17]  \n",
    "y = df_original.iloc[:, 17] \n",
    "\n",
    "# Cria o balanceador SMOTE\n",
    "smote_bal = SMOTE(random_state = seed)\n",
    "\n",
    "# Aplica o balanceador\n",
    "X_res, y_res = smote_bal.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Gráfico do quantitativo da variável alvo \n",
    "ax = sns.countplot(x = \"species\", data = dados, palette = \"Greens_d\");\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() + 0.15, p.get_height() + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Checar se exite IDs duplicados. Comparar o resultado com a quantidade linhas do dataframe. \"id\" é o nome da coluna\n",
    "dados.species.value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Verifica o total de valores únicos por coluna\n",
    "# Variáveis com poucos valores únicos provavelmente é uma variável categórica. Por outro lado, uma variável com muitos valores únicos provavelmente é uma variável numérica.\n",
    "dados.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando dados missing\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "O tratamento de dados missing é obrigatório. A presença dados NA prejudica o modelo. <br>\n",
    "    Verificar se a variável com valor NA tem relação com outras variáveis antes de qualquer Modificação. <br>\n",
    "    A imputação é realizada somente em variáveis quantitativas numéricas. Para variáveis qualitativas é melhor excluir a linha.<br>\n",
    "    Quando o data set apresenta uma quantidade maior ou igual a 5%  de valores missing é melhor aplicar uma regra de imputação. Por outro lado, uma quantidade menor do que 5% é melhor apagar os dados missing.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Verificar se existem dados missing NA\n",
    "#dados.values.any()\n",
    "#dados.isna() \n",
    "dados.isnull().sum() # Retorna a quantida de NA por coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Retornando somente as linhas com valores NA\n",
    "dados[dados.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imputation 1\n",
    "# A função fillna percorre todo o dataset substituindo todos os valores NA com o valor desejado\n",
    "n = 0\n",
    "dados = dados.fillna(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imputation 2\n",
    "# Substitui todos os valores NA com a média da respectiva coluna\n",
    "dados = dados.fillna(dados.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Apaga todas as linhas do dataset com valores NA\n",
    "dados = dados.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorando relacionamento entre as variáveis: Matriz de Correlação\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "Observar principalmente o coeficiente de correlação da variável alvo com as outras variáveis <br>\n",
    "A correlação tem o mesmo conceito de grandezas diretamente e inversamente proporcionais. <br> \n",
    "Obs.: a correlação não gera causalidade. <br>\n",
    "Visualizando relacionamento entre as variáveis: Scatterplot (analisa a relação entre duas variáveis x (independente) e y (dependente). <br>\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = dados.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_width\n",
       "0            3.5\n",
       "1            3.0\n",
       "2            3.2\n",
       "3            3.1\n",
       "4            3.6\n",
       "..           ...\n",
       "145          3.0\n",
       "146          2.5\n",
       "147          3.0\n",
       "148          3.4\n",
       "149          3.0\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.iloc[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df[\"Espécie\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dados[\"especie\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Econding\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "Converter as vaiáveis valores numéricos \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "especie = pd.Series([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# running a for loop and asigning some values to data \n",
    "for i in range(len(dados)): \n",
    "    if dados[\"species\"][i] == \"virginica\": \n",
    "        especie[i] = 0\n",
    "  \n",
    "    elif dados[\"species\"][i] == \"setosa\": \n",
    "        especie[i] = 1\n",
    "      \n",
    "    else: \n",
    "        especie[i] = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# inserting new column with values of list made above         \n",
    "dados.insert(5,\"especie\", especie) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Cria o encoder\n",
    "lb = LabelEncoder()\n",
    "\n",
    "# Aplica o encoder nas variáveis que estão com string\n",
    "df_original['Month'] = lb.fit_transform(df_original['Month'])\n",
    "df_original['VisitorType'] = lb.fit_transform(df_original['VisitorType'])\n",
    "\n",
    "# Remove valores missing eventualmente gerados\n",
    "df_original.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Cria o encoder\n",
    "lb = LabelEncoder()\n",
    "\n",
    "# Aplica o encoder na variável target\n",
    "dados[\"species\"] = lb.fit_transform(dados.species)\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# pesquisar sobre OneHotEncoder para conversão das variáveis categóricas em números.\n",
    "# não basta converter as variáveis em texto para o tipo númerico. As variáveis devem continuar como categórigas, mesmo sendo do tipo numérico.\n",
    "# pesquisar sobre o método pd.get_dummies\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "especies = [\"virginica\", \"setosa\", \"versicolor\"]\n",
    "\n",
    "enc = OneHotEncoder(categories=[especies])\n",
    "\n",
    "X = dados.species.values.reshape(-1, 1)\n",
    "enc.fit(X)\n",
    "enc.transform(dados.species.values.reshape(-1, 1))\n",
    "SMOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dados.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Criando um Correlation Plot\n",
    "def visualize_correlation_matrix(data, hurdle = 0.0):\n",
    "    R = np.corrcoef(data, rowvar = 0)\n",
    "    R[np.where(np.abs(R) < hurdle)] = 0.0\n",
    "    heatmap = plt.pcolor(R, cmap = mpl.cm.coolwarm, alpha = 0.8)\n",
    "    heatmap.axes.set_frame_on(False)\n",
    "    heatmap.axes.set_yticks(np.arange(R.shape[0]) + 0.5, minor = False)\n",
    "    heatmap.axes.set_xticks(np.arange(R.shape[1]) + 0.5, minor = False)\n",
    "    heatmap.axes.set_xticklabels(variables, minor = False)\n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap.axes.set_yticklabels(variables, minor = False)\n",
    "    plt.tick_params(axis = 'both', which = 'both', bottom = 'off', top = 'off', left = 'off', right = 'off') \n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Analisar os dados setando a variável alvo (quando categórica) como índice\n",
    "df = dados.groupby([\"species\"])\n",
    "# df.aggregate([np.mean, np.median, np.min, np.max, np.sum, np.size])\n",
    "df.aggregate(np.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.aggregate([np.min, np.max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "#Criando o gráfico\n",
    "box1 = go.Box(y = dados['preg'],\n",
    "              name = 'preg',\n",
    "              marker = {'color': '#cd191e'})\n",
    "box2 = go.Box(y = dados['plas'],\n",
    "              name = 'plas',\n",
    "              marker = {'color': '#f39c12'})\n",
    "box3 = go.Box(y = dados['test'],\n",
    "              name = 'test',\n",
    "              marker = {'color': '#7f7f7f'})\n",
    "box4 = go.Box(y = dados['mass'],\n",
    "              name = 'mass',\n",
    "              marker = {'color': '#836FFF'})\n",
    "box5 = go.Box(y = dados['pedi'],\n",
    "              name = 'pedi',\n",
    "              marker = {'color': '#BDB76B'})\n",
    "box6 = go.Box(y = dados['age'],\n",
    "              name = 'age',\n",
    "              marker = {'color': '#B0E0E6'})\n",
    "\n",
    "data = [box1, box2, box3, box4, box5, box6]\n",
    "# Criando Layout\n",
    "layout = go.Layout(title='Analisando as variáveis',\n",
    "                   yaxis={'title':'Valor'})\n",
    "# Criando figura que será exibida\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "# Exibindo figura/gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Criar uma tabela cruzada com variáveis categóricas e analisar a relação entre elas. Tipo de Visitante x Revenue\n",
    "pd.crosstab(df['VisitorType'], df['Revenue']).plot(kind = 'bar', \n",
    "                                                   figsize = (15, 5), \n",
    "                                                   color = ['red', 'green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Função que normaliza os dados utilizando a técnica de mínimo e máximo\n",
    "# col_name recebe uma lista de variáveis que serão normalizadas\n",
    "# pddata recebe o dataset\n",
    "# valoresAltos setado como True, significa que a normalização será feita com valores mais ALTOS\n",
    "def normaliza(col_name, pddata, valoresAltos = False):\n",
    "    pddata[col_name] -= pddata[col_name].min()\n",
    "    pddata[col_name] /= pddata[col_name].max()\n",
    "    if valoresAltos:\n",
    "        pddata[col_name] = 1 - pddata[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Chamando a função de normalização\n",
    "# É uma boa prática fazer uma cópia dos dados com o objetivo de manter os dados originais\n",
    "lista_colunas = ['preg', 'plas', 'test', 'mass', 'pedi', 'age']\n",
    "dadosNormalizados = dados.copy()\n",
    "# Normalizando com valores mais BAIXOS\n",
    "normaliza(lista_colunas, dadosNormalizados)\n",
    "dadosNormalizados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Padronizando os dados (0 para a média, 1 para o desvio padrão)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "array = dadosNormalizados.values\n",
    "\n",
    "# Separando o array em componentes de input e output \n",
    "X = array[:,[0, 1, 4, 5, 6, 7]]\n",
    "variavelAlvo = array[:,8]\n",
    "\n",
    "# Gerando o novo padrão\n",
    "scaler = StandardScaler().fit(X)\n",
    "dadosNormalizadosPadronizados = scaler.transform(X)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", dados.values)\n",
    "print(\"\\nDados Padronizados: \\n\\n\", dadosNormalizadosPadronizados[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pesquisar o método SelectKbest para selecionar as melhores variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando o Randon Forest para seleção de variáveis\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    " O algoritmo Randon Forest é excelente para escolher as melhores variáveis\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados utilizando dados de treino e dados de teste  \n",
    "num_observ = len(dados)\n",
    "# 4 é o número de variáveis (colunas)\n",
    "X = dados[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]].values.reshape((num_observ, 4)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "Y = dados['species'].values # y pode ser um vetor\n",
    "\n",
    "# Utilizar matriz Numpy é melhor otmizado na memória do computador do que o Pandas, principalmente quando o dataset for grande\n",
    "\n",
    "# o random_state é útil durante os teste para reproduzir os mesmos resultados após fechar  e abrir o Jupyter Lab. Pode ser retirando na versão final do modelo.\n",
    "# Divide os dados em treino e teste\n",
    "# Quanto menor o tamanho do dataset maior deve ser o tamanho dos dados de treino\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, shuffle = True, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dadosTreino = pd.DataFrame(X_train)\n",
    "dadosTreino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dados.values\n",
    "\n",
    "# Definindo os valores para o número de folds\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = RandomForestClassifier()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo a importância\n",
    "importances = modelo.feature_importances_\n",
    "indices = np.argsort(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém os índices\n",
    "ind=[]\n",
    "for i in indices:\n",
    "    ind.append(dados.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot da Importância dos Atributos\n",
    "plt.figure(1)\n",
    "plt.title('Importância dos Atributos')\n",
    "plt.barh(range(len(indices)), importances[indices], color = 'b', align = 'center')\n",
    "plt.yticks(range(len(indices)),ind)\n",
    "plt.xlabel('Importância Relativa')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(dados, x=\"petal_length\", y=\"petal_width\", color=\"species\")\n",
    "fig.update_traces(marker=dict(size=12,\n",
    "                              line=dict(width=2,\n",
    "                              color='DarkSlateGrey')),\n",
    "                              selector=dict(mode='markers'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se as classes estão com divisão balanceada, ou seja, com a mesma quantidade para cada classe.\n",
    "# fazer a mesma verificação nos dados de treino. Oversampling aumenta a quantidade da classe com menor quantidade. Undersampling diminui a quantidade da classe com maior quantidade.\n",
    "# Quantitativo da variável alvo \n",
    "dadosTreino = pd.DataFrame(Y_train)\n",
    "dadosTreino[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    " O algoritmo KMeans agrupa os dados tentando separar amostras em n grupos de variância igual, minimizando um critério conhecido como inércia ou soma dos quadrados dentro do cluster. Este algoritmo requer que o número de clusters seja especificado. Ele se adapta bem a um grande número de amostras e tem sido usado em uma grande variedade de áreas de aplicação em muitos campos diferentes. <br>\n",
    "    Para utilizar o K-means os dados devem estar padronizados.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dados.copy()\n",
    "# Excluir colunas\n",
    "df = df.drop(['species'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(df)\n",
    "especies = kmeans.labels_\n",
    "#df[\"especies\"] = especies\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico do quantitativo da variável alvo \n",
    "ax = sns.countplot(x = \"especies\", data = df, palette = \"Greens_d\");\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() + 0.15, p.get_height() + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = kmeans.predict(df)\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descobrindo a melhor quantidade de clusters\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pylab\n",
    "\n",
    "# Diferenças nos clusters de acordo com os valores de K\n",
    "pylab.rcParams['figure.figsize'] = (20.0, 4.0)\n",
    "\n",
    "# os valores para k é a quantidade de clusters\n",
    "for K in [2, 3, 4]:\n",
    "    \n",
    "    # Criando o classificador e construindo o modelo\n",
    "    modelo = KMeans(n_clusters = K, random_state = 101)\n",
    "    y_pred = modelo.fit_predict(df)\n",
    "    \n",
    "    plt.subplot(1, 3, K-1)\n",
    "    plt.title(\"K-means, K=%s\" % K)\n",
    "    plt.scatter(df.petal_length, df.petal_width, c = y_pred, edgecolors = 'none')\n",
    "    # 2 e 3 são os centróides das variáveis petal_length e petal_width\n",
    "    plt.scatter(modelo.cluster_centers_[:,2], modelo.cluster_centers_[:,3], marker = 'x', color = 'r', s = 100, linewidths = 4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de clusterização\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "    As métricas de clusterização aqui utilizadas são homogeneidade, completude e Medida V.<br>\n",
    "    Um resultado de cluster satisfaz a homogeneidade se todos os seus clusters contiverem apenas pontos de dados que são membros de uma única classe. <br>\n",
    "    Um resultado de cluster satisfaz a completude se todos os pontos de dados que são membros de uma determinada classe são elementos do mesmo cluster. <br>\n",
    "    Ambas as pontuações têm valores positivos entre 0,0 e 1,0, sendo desejáveis valores maiores.<br>\n",
    "    Medida V é a média entre homogeneidade e completude. <br>\n",
    "    Só é possível utilizar essa métricas se a variável alvo for previamente conhecida. Caso contrário, não será porssível utiliza-las. <br>\n",
    "    Talvez seja interessante utiliza-las para validar a quantidade de classes atribuídas ao dataset. Ou seja, verificar se o dataset possui o número adequado de classes. <br>\n",
    "    \n",
    "    Inertia = Soma das distâncias das amostras para o seu centro de agrupamento mais próximo.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import homogeneity_completeness_v_measure\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pylab\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 4.0)\n",
    "\n",
    "# Lista com os valores de K\n",
    "valores_k = range(2, 10)\n",
    "\n",
    "# Lista para receber as métricas\n",
    "HCVs = []\n",
    "\n",
    "\n",
    "for K in valores_k:\n",
    "    \n",
    "    # Criando o classificador e fazendo previsões sobre o cluster para cada ponto de dados\n",
    "    y_pred = KMeans(n_clusters = K, random_state = 101).fit_predict(df)\n",
    "    \n",
    "    # Calculando as métricas\n",
    "    HCVs.append(homogeneity_completeness_v_measure(dados.species, y_pred))\n",
    "\n",
    "plt.plot(valores_k, [el[0] for el in HCVs], 'b', label = 'Homogeneidade')\n",
    "plt.plot(valores_k, [el[1] for el in HCVs], 'g', label = 'Completude')\n",
    "plt.plot(valores_k, [el[2] for el in HCVs], 'r', label = 'Medida V')\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel(\"Valor de K\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(loc = 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inertia = Soma das distâncias das amostras para o seu centro de agrupamento mais próximo. Qaunto menor o  valor da Inertia melhor será a quatidade de clusters. \n",
    "# Muito cuidado, pois a Inertia deve ser comparada com outras métricas\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Lista de valores de K\n",
    "Ks = range(2, 10)\n",
    "\n",
    "# Lista para as métricas\n",
    "valores_metrica = []\n",
    "\n",
    "# Loop por diferentes modelos com diferentes valores de K\n",
    "for K in Ks:\n",
    "    modelo = KMeans(n_clusters = K, random_state = 101)\n",
    "    modelo.fit(df)\n",
    "    valores_metrica.append(modelo.inertia_)\n",
    "\n",
    "plt.plot(Ks, valores_metrica, 'o-')\n",
    "plt.xlabel(\"Valor de K\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bandwidth = Comprimento da Interação entre os exemplos, também conhecido como a largura de banda do algoritmo.\n",
    "\n",
    "# Cria o modelo\n",
    "modelo_v1 = MeanShift(bandwidth=0.85)\n",
    "\n",
    "# Treina o modelo\n",
    "previsoesMeanShift = modelo_v1.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coleta os labels, centróides e número de clusters\n",
    "labels = modelo_v1.labels_\n",
    "cluster_centers = modelo_v1.cluster_centers_\n",
    "n_clusters_ = labels.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab\n",
    "\n",
    "# Diferenças nos clusters de acordo com os valores de K\n",
    "pylab.rcParams['figure.figsize'] = (6.0, 4.0)\n",
    "\n",
    "for k  in zip(range(n_clusters_)):\n",
    "    cluster_center = cluster_centers[k]\n",
    "    plt.scatter(df.petal_length, df.petal_width, c= previsoesMeanShift, edgecolors = 'none')# col + '.')\n",
    "    # 2 e 3 são os centróides das variáveis petal_length e petal_width\n",
    "    plt.scatter(cluster_centers[:,2], cluster_centers[:,3], marker = 'x', color = 'r', s = 100, linewidths = 4)\n",
    "    plt.title('Número Estimado de Clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Etapa 3 - Criando, treinando e avaliando os Modelos </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criar primeiramente um modelo simples e depois alterar um parâmetro de cada vez, documentando e salvando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaAlgoritmo = {\"Algoritmo\": [\"Regressão Logística\", \"Linear Discriminant Analysis\", \"KNN\", \"Naive Bayes\", \"CART\", \"SVM\"],\n",
    "                   \"Erros\": [\"-\", \"-\", \"-\", \"-\", \"-\", \"-\",]}\n",
    "pdComparaAlgoritmo = pd.DataFrame(comparaAlgoritmo)\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "# Dicionário de métricas e metadados\n",
    "# primeiro coloca-se como parâmetro as previsões e depois os valores reais da variável alvo, com exceção da métrica AUC\n",
    "# As técnicas Precision e Recall devem ter valores próximos. Caso contrário, é possível que o modelo aprendeu mais de uma clase do que de outra.\n",
    "# f1 score é uma proporção entre Precision e Recall\n",
    "\n",
    "SVM_dict_v1 = {'Modelo':'SVM',\n",
    "               'Versão':'1',\n",
    "               'Kernel':'Linear',\n",
    "               'Precision':precision_score(previsoes_v1, y_teste),\n",
    "               'Recall':recall_score(previsoes_v1, y_teste),\n",
    "               'F1 Score':f1_score(previsoes_v1, y_teste),\n",
    "               'Acurácia':accuracy_score(previsoes_v1, y_teste),\n",
    "               'AUC':roc_auc_score(y_teste, previsoes_v1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print\n",
    "print(\"Métricas em Teste:\\n\")\n",
    "SVM_dict_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "Algoritmo Linear. O algoritmo de Regressão Logística assume que seus dados estão em uma Distribuição Normal para valores numéricos que podem ser modelados com classificação binária.\n",
    "As variáveis devem estar na mesma escala\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "previsoes = cross_val_predict(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0],erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdComparaAlgoritmo.iloc[0,1] = erros\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "Algoritmo Linear. Técnica estatística para classificação binária. Também assume que os dados estão em Distribuição Normal.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdComparaAlgoritmo.iloc[1,1] = erros\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN - K-Nearest Neighbors\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "Algoritmo Não-Linear que utiliza uma métrica de distância para encontrar o valor de K mais adequado as instâncias do dataset de treino. Os dados devem estar normalizados Os outliers devem ser tratados, pois influenciam bastante no algoritmo. É muito importante definir a quantidade de k (número de vizinhos). O algoritmo funciona melhor valores ímpares para k. Visto que, valores pares podem gerar empate e cair em votação prejudicando o modelo.\n",
    "\n",
    "Os scripts abaixo ajudam a encontrar o melhor valor de k\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados de treino em dados de treino e dados de validação\n",
    "treinoData, validData, treinoLabels, validLabels = train_test_split(X_train, \n",
    "                                                                    Y_train, \n",
    "                                                                    test_size = 0.1, \n",
    "                                                                    random_state = 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range de valores de k que iremos testar\n",
    "kVals = range(1, 30, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista vazia para receber as acurácias\n",
    "acuracias = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop em todos os valores de k para testar cada um deles\n",
    "for k in kVals:\n",
    "    \n",
    "    # Treinando o modelo KNN com cada valor de k\n",
    "    modeloKNN = KNeighborsClassifier(n_neighbors = k)\n",
    "    modeloKNN.fit(X_train, Y_train)\n",
    "          \n",
    "    # Avaliando o modelo e atualizando a lista de acurácias\n",
    "    score = modeloKNN.score(validData, validLabels)\n",
    "    print(\"Com valor de k = %d, a acurácia é = %.2f%%\" % (k, score * 100))\n",
    "    acuracias.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo o valor de k que apresentou a maior acurácia\n",
    "i = np.argmax(acuracias)\n",
    "print(\"O valor de k = %d alcançou a mais alta acurácia de %.2f%% nos dados de validação!\" % (kVals[i], \n",
    "                                                                                             acuracias[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdComparaAlgoritmo.iloc[2,1] = erros\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "Algoritmo Não-Linear, probalístico. Calcula a Probabilidade de cada classe e a probabilidade condicional de cada classe dado uma variável de entrada. As probabilidades são então estimadas para os novos dados e multiplicadas, assumindo que são independentes (suposição simples ou Naive). \n",
    "Assume dados em distirbuição Gaussiana (Normal)\n",
    "Excelente para previsões em tempo real.\n",
    "O Naive Bayes possui apenas um parâmetro (priori), sendo assim exige uma boa preparação dos dados.\n",
    "Muito útil para dados no formato de texto.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = GaussianNB()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdComparaAlgoritmo.iloc[3,1] = erros\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Support Vector Machines\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "O objetivo deste algoritmo é buscar uma linha que melhor separa duas classes dentro de um conjunto de dados. As instâncias de dados que estão mais próximas desta linha que separa as classes, são chamadas support vectors. O SVM tem sido estendido para suportar multiclasses.<br>\n",
    "\n",
    "    Support Vector Machines são algoritmos de classificação muito poderosos. Quando usados em conjunto com “Random forest” e outras ferramentas de aprendizagem de máquina, dão uma dimensão muito diferente para montagem de modelos. Assim, eles se tornam cruciais para os casos em que é necessária um poder de previsão muito elevado. Esses algoritmos são um pouco mais difíceis de visualizar devido à complexidade na formulação.\n",
    "</p>\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = SVC()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdComparaAlgoritmo.iloc[5,1] = erros\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos de árvore de decisão\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "A árvore é criada de cabeça para baixo, ou seja, a raiz (ponto de partida) é a parte de cima e as folhas em baixo. Os nós representam os atributos. A decisão ocorre nas folhas.  Existem diversos algoritmos de decisão, como por exmplo, CART. Podem ser usados em problemas de Regressão e Classificação.<br>\n",
    "    Fazer o prunning da árvore após o treinamento do modelo. <br>\n",
    "    Atribuir pesos aos erros. Atribuir o maior peso aos erros mais críticos, ou seja, aqueles que se acontecerem trarão mais prejuízo ao negócio.\n",
    "    Estudar melhor Entropia e Índice Gini\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART (Classification and Regression Trees)\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "Algoritmo Não-Linear. O algoritmo CART constrói uma árvore binária a partir do dataset de treino. Cada atributo e cada valor de cada atributo são avaliados com o objetivo de reduzir a função de custo (Cost Function).\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = DecisionTreeClassifier()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdComparaAlgoritmo.iloc[4,1] = erros\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "Os 5 principais parâmetros em Modelos de Random Forest são: <br>\n",
    "    \n",
    "criterion{“gini”, “entropy”}, default=”gini” <br>\n",
    "\n",
    "n_estimators - número de árvores na floresta, quanto maior, melhor! Cada árvore é um modelo. No final é escolhido o melhor modelo <br>\n",
    "\n",
    "max depth - o padrão é 'none' e nesse caso árvores completas são criadas. Ajustando esse parâmetro pode ajudar a evitar overfitting. <br>\n",
    "\n",
    "max_features - diferentes valores devem ser testados, pois este parâmetro impacta na forma como os modelos RF distribuem os atributos pelas árvores. <br>\n",
    "\n",
    "criterion - define a forma como o algoritmo fará a divisão dos atributos e a classificação dos nós em cada árvore. <br>\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = RandomForestClassifier()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mudar o índice\n",
    "pdComparaAlgoritmo.iloc[4,1] = erros\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "    Bagging é usado para construção de múltiplos modelos (normalmente do mesmo tipo) a partir de diferentes subsets no dataset de treino. <br>\n",
    "    Um classificador Bagging é um meta-estimador ensemble que faz o fit de classificadores base, cada um em subconjuntos aleatórios do conjunto de dados original e, em seguida, agrega suas previsões individuais (por votação ou por média) para formar uma previsão final.<br>\n",
    "    Tal meta-estimador pode tipicamente ser usado como uma maneira de reduzir a variância de um estimador (por exemplo, uma árvore de decisão), introduzindo a randomização em seu procedimento de construção e fazendo um ensemble (conjunto) a partir dele.<br>\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "# modelo = BaggingClassifier()\n",
    "# É possível especificar qual algoritmo utilizar para criar os modelos\n",
    "modelo = BaggingClassifier(LogisticRegression())\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mudar o índice\n",
    "pdComparaAlgoritmo.iloc[4,1] = erros\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremely Randomized Trees (ExtraTrees)\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "    Método esemble com funcionamento muito pareceido ao Randon Forest, com a diferença que as árvores são criadas de forma randômica\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = ExtraTreesClassifier()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mudar o índice\n",
    "pdComparaAlgoritmo.iloc[4,1] = erros\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "    Um classificador AdaBoost é um meta-estimador que começa ajustando um classificador no conjunto de dados original e depois ajusta cópias adicionais do classificador no mesmo conjunto de dados, mas onde os pesos das instâncias classificadas incorretamente são ajustados para que os classificadores subsequentes se concentrem mais em casos difíceis.<br>\n",
    "    learning_rate é um parâmetro muito importante. Alterá-lo pode melhor o resultado.\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo = AdaBoostClassifier()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo, X, Y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mudar o índice\n",
    "pdComparaAlgoritmo.iloc[4,1] = erros\n",
    "pdComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackingClassifier\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "    A generalização empilhada é um método para combinar estimadores para reduzir seus vieses. Mais precisamente, as previsões de cada estimador individual são empilhadas e usadas como entrada para um estimador final para calcular a previsão. Este estimador final é treinado por meio de validação cruzada.\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "# Definir os algoritmos que serão empilhados\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=10, random_state=42)), ('svr', make_pipeline(StandardScaler(), SVC(random_state=42)))]\n",
    "\n",
    "modeloStacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# Treinando o modelo\n",
    "modeloStacking.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "previsoes = modeloStacking.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gradient Boosting ou Gradient Boostted Regression Trees (GBRT)\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "   \n",
    "    Gradient Boosting ou Gradient Boostted Regression Trees (GBRT) é uma técnica de aprendizagem estatística não-paramétrica usada para problemas de classificação e regressão. \n",
    "\n",
    "Gradient Boosting = Gradient Descent + Boosting.  <br>\n",
    "\n",
    "http://deeplearningbook.com.br/aprendizado-com-a-descida-do-gradiente/  <br>\n",
    "\n",
    "Basicamente 3 etapas são realizadas na construção do modelo:  <br>\n",
    "\n",
    "1- Gera um regressor  <br>\n",
    "\n",
    "2- Computa o erro residual  <br>\n",
    "\n",
    "3- Aprende a prever o resíduo <br>\n",
    "    \n",
    "    Parâmetros mais importantes:\n",
    "    Número de árvores de regressão (n_estimators)\n",
    "    Profundidade de cara árvore (max_depth)\n",
    "    loss function (loss)\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo\n",
    "modelo = GradientBoostingClassifier(n_estimators = 100, learning_rate = 1.0, random_state = 0)\n",
    "\n",
    "# Treina o classificador\n",
    "modelo.fit(X_train, Y_train)\n",
    "\n",
    "# Calcula a acurácia (score)\n",
    "modelo.score(X_test, Y_test)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0], erros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eXtreme Gradient Boosting \n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "   \n",
    "    eXtreme Gradient Boosting é uma biblioteca de código aberto que fornece uma otimização eficiente e eficaz do algoritmo Gradient Boosting, sendo mais rápido. \n",
    "    \n",
    "    https://xgboost.readthedocs.io/en/latest/python/python_intro.html#\n",
    "    \n",
    "    Verificar o formato da Matriz. A matriz esparça não é a melhor opção para o algoritmo. A melhor alternativa é utilizar uma matriz densa.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Automatizando os modelos\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "  \n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dos módulos\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Criando e Preparando a lista de modelos\n",
    "modelos = []\n",
    "modelos.append(('LR', LogisticRegression())) # Regressão Logistica\n",
    "modelos.append(('LDA', LinearDiscriminantAnalysis())) # Linear Discriminant Analysis\n",
    "modelos.append(('NB', GaussianNB())) # Naibe Bayes\n",
    "modelos.append(('KNN', KNeighborsClassifier())) # KNN - K-Nearest Neighbors\n",
    "modelos.append(('CART', DecisionTreeClassifier())) # Classification and Regression Trees\n",
    "modelos.append(('SVM', SVC())) # Support Vector Machines\n",
    "modelos.append(('XGB', XGBClassifier())) # XGBoost\n",
    "\n",
    "# Treinando e avaliando cada modelo em um loop\n",
    "resultados = []\n",
    "nomes = []\n",
    "\n",
    "# Definindo os valores para os folds\n",
    "num_folds = 11\n",
    "seed = 7\n",
    "\n",
    "for nome, modelo in modelos:\n",
    "    kfold = KFold(n_splits = num_folds, random_state = seed)\n",
    "    cv_results = cross_val_score(modelo, dadosNormalizadosPadronizados, variavelAlvo, cv = kfold, scoring = 'accuracy')\n",
    "    resultados.append(cv_results)\n",
    "    nomes.append(nome)\n",
    "    msg = \"%s: %f (%f)\" % (nome, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# Boxplot para comparar os algoritmos\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparação de Algoritmos de Classificação')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(resultados)\n",
    "ax.set_xticklabels(nomes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Etapa 5 - Otimizando a Performance do Modelo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de Hyperparâmetros\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "       Todos os algoritmos de Machine Learning são parametrizados, o que significa que você pode ajustar a performance do seu modelo preditivo, através do tuning (ajuste fino) dos parâmetros. Seu trabalho é encontrar a melhor combinação entre os parâmetros em cada algoritmo de Machine Learning. Esse processo também é chamado de Otimização de Hyperparâmetros. O scikit-learn oferece dois métodos para otimização automática dos parâmetros: Grid Search Parameter Tuning e Random Search Parameter Tuning. \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Parameter Tuning\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "       Este método realiza metodicamente combinações entre todos os parâmetros do algoritmo, criando um grid. Cada algoritmo possui seus parâmetros e o Grid Search precisa ser ajustado de acordo àquele utilizado.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otimizando o algoritmo de Regerssão Logistica\n",
    "\n",
    "# Import dos módulos\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "valores_grid = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Criando o grid\n",
    "# n_jobs é o número de threads no processador\n",
    "modelo_LR = GridSearchCV(estimator = modelo, param_grid = valores_grid, n_jobs = 4)\n",
    "modelo_LR.fit(X_train, Y_train)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (modelo_LR.best_score_ * 100))\n",
    "print(\"Melhores Parâmetros do Modelo:\\n\", modelo_LR.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salva o melhor modelo\n",
    "modelo_final  = modelo_LR.best_estimator_\n",
    "modelo_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com os dados de teste\n",
    "previsoes = modelo_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaResultado = pd.DataFrame(Y_test)\n",
    "comparaResultado[\"previsões\"] = previsoes\n",
    "comparaResultado.rename(columns = {0:\"Dados teste\"}, inplace = True)\n",
    "#comparaResultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário\n",
    "print(classification_report(Y_test, previsoes))\n",
    "print(confusion_matrix(Y_test, previsoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidades de previsões erradas\n",
    "erros = (comparaResultado[\"Dados teste\"] != previsoes).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o resultado\n",
    "print(\"Total de Observações: %d - Total de Previsões Incorretas : %d\" \n",
    "      % (comparaResultado.shape[0],erros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search CV\n",
    "<details><summary>CLICK</summary>\n",
    "<p>\n",
    "       Este método gera amostras dos parâmetros dos algoritmos a partir de uma distribuição randômica uniforme para um número fixo de iterações. Um modelo é construído e testado para cada combinação de parâmetros.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "valores_grid = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Definindo os valores que serão testados\n",
    "seed = 7\n",
    "iterations = 14\n",
    "\n",
    "# Criando o grid\n",
    "rsearch = RandomizedSearchCV(estimator = modelo, \n",
    "                             param_distributions = valores_grid, \n",
    "                             n_iter = iterations, \n",
    "                             random_state = seed)\n",
    "rsearch.fit(X_train, Y_train)\n",
    "\n",
    "# Print dos resultados\n",
    "print(\"Acurácia: %.3f\" % (rsearch.best_score_ * 100))\n",
    "print(\"Melhores Parâmetros do Modelo:\\n\", rsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Etapa 6 -  Salvando/Carregando o modelo</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvando o modelo\n",
    "arquivo = 'modelos/modelo_classificador_final.sav'\n",
    "pickle.dump(modelo_LR, open(arquivo, 'wb'))\n",
    "print(\"Modelo salvo!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o arquivo\n",
    "modelo_classificador_final = pickle.load(open(arquivo, 'rb'))\n",
    "#modelo_producao = modelo_classificador_final.score(X_teste, Y_teste)\n",
    "print(\"Modelo carregado!\")\n",
    "\n",
    "# Print do resultado\n",
    "#print(\"Acurácia: %.3f\" % (modelo_producao.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
