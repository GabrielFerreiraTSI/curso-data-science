{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Two Sigma Financial Modeling</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Definição do Problema de Negócio\n",
    "<details>\n",
    "    <summary>\n",
    "        <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>&nbsp;&nbsp;Clique para mais detalhes</a>\n",
    "    </summary>\n",
    "    <br>\n",
    "\n",
    "\n",
    "    \n",
    "Endereço do conjunto de dados: https://www.kaggle.com/competitions/two-sigma-financial-modeling/overview\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Coletando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "O sistema nÆo pode encontrar o caminho especificado.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvirtualdisplay in c:\\users\\pinad\\anaconda3\\lib\\site-packages (3.0)\n",
      "Requirement already satisfied: gym[atari] in c:\\users\\pinad\\anaconda3\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from gym[atari]) (1.20.3)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from gym[atari]) (0.0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from gym[atari]) (1.6.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0; python_version < \"3.10\" in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from gym[atari]) (5.0.0)\n",
      "Requirement already satisfied: ale-py~=0.8.0; extra == \"atari\" in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from gym[atari]) (0.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0; python_version < \"3.10\"->gym[atari]) (3.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from ale-py~=0.8.0; extra == \"atari\"->gym[atari]) (5.10.0)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.11\" in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from ale-py~=0.8.0; extra == \"atari\"->gym[atari]) (3.7.4.3)\n",
      "\n",
      "Requirement already satisfied: gym[box2d] in c:\\users\\pinad\\anaconda3\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from gym[box2d]) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from gym[box2d]) (1.20.3)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from gym[box2d]) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0; python_version < \"3.10\" in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from gym[box2d]) (5.0.0)\n",
      "Collecting pygame==2.1.0; extra == \"box2d\"\n",
      "  Using cached pygame-2.1.0-cp38-cp38-win_amd64.whl (4.8 MB)\n",
      "Requirement already satisfied: swig==4.*; extra == \"box2d\" in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from gym[box2d]) (4.1.0)\n",
      "Collecting box2d-py==2.3.5; extra == \"box2d\"\n",
      "  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\pinad\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0; python_version < \"3.10\"->gym[box2d]) (3.4.0)\n",
      "Building wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py): started\n",
      "  Building wheel for box2d-py (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for box2d-py\n",
      "Failed to build box2d-py\n",
      "Installing collected packages: pygame, box2d-py\n",
      "    Running setup.py install for box2d-py: started\n",
      "    Running setup.py install for box2d-py: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\pinad\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\pinad\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dcr_n5jt\\\\box2d-py\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\pinad\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dcr_n5jt\\\\box2d-py\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\pinad\\AppData\\Local\\Temp\\pip-wheel-jjpkeu42'\n",
      "       cwd: C:\\Users\\pinad\\AppData\\Local\\Temp\\pip-install-dcr_n5jt\\box2d-py\\\n",
      "  Complete output (28 lines):\n",
      "  Using setuptools (version 50.3.1.post20201107).\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  creating build\\lib.win-amd64-3.8\\Box2D\n",
      "  copying library\\Box2D\\Box2D.py -> build\\lib.win-amd64-3.8\\Box2D\n",
      "  copying library\\Box2D\\__init__.py -> build\\lib.win-amd64-3.8\\Box2D\n",
      "  creating build\\lib.win-amd64-3.8\\Box2D\\b2\n",
      "  copying library\\Box2D\\b2\\__init__.py -> build\\lib.win-amd64-3.8\\Box2D\\b2\n",
      "  running build_ext\n",
      "  building 'Box2D._Box2D' extension\n",
      "  swigging Box2D\\Box2D.i to Box2D\\Box2D_wrap.cpp\n",
      "  C:\\Users\\pinad\\anaconda3\\Scripts\\swig.exe -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library\\Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D\\Box2D_wrap.cpp Box2D\\Box2D.i\n",
      "  Box2D\\Common\\b2Math.h(67) : Warning 302: Identifier 'b2Vec2' redefined by %extend (ignored),\n",
      "  Box2D\\Box2D_math.i(47) : Warning 302: %extend definition of 'b2Vec2'.\n",
      "  Box2D\\Common\\b2Math.h(158) : Warning 302: Identifier 'b2Vec3' redefined by %extend (ignored),\n",
      "  Box2D\\Box2D_math.i(168) : Warning 302: %extend definition of 'b2Vec3'.\n",
      "  Box2D\\Common\\b2Math.h(197) : Warning 302: Identifier 'b2Mat22' redefined by %extend (ignored),\n",
      "  Box2D\\Box2D_math.i(301) : Warning 302: %extend definition of 'b2Mat22'.\n",
      "  Box2D\\Common\\b2Math.h(271) : Warning 302: Identifier 'b2Mat33' redefined by %extend (ignored),\n",
      "  Box2D\\Box2D_math.i(372) : Warning 302: %extend definition of 'b2Mat33'.\n",
      "  Box2D\\Collision\\b2DynamicTree.h(44) : Warning 312: Nested union not currently supported (ignored).\n",
      "  Box2D\\Common\\b2Settings.h(144) : Warning 506: Can't wrap varargs with keyword arguments enabled\n",
      "  Box2D\\Common\\b2Math.h(91) : Warning 509: Overloaded method b2Vec2::operator ()(int32) effectively ignored,\n",
      "  Box2D\\Common\\b2Math.h(85) : Warning 509: as it is shadowed by b2Vec2::operator ()(int32) const.\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for box2d-py\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\pinad\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\pinad\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dcr_n5jt\\\\box2d-py\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\pinad\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dcr_n5jt\\\\box2d-py\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\pinad\\AppData\\Local\\Temp\\pip-record-d936to6t\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\pinad\\anaconda3\\Include\\box2d-py'\n",
      "         cwd: C:\\Users\\pinad\\AppData\\Local\\Temp\\pip-install-dcr_n5jt\\box2d-py\\\n",
      "    Complete output (28 lines):\n",
      "    Using setuptools (version 50.3.1.post20201107).\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.8\n",
      "    creating build\\lib.win-amd64-3.8\\Box2D\n",
      "    copying library\\Box2D\\Box2D.py -> build\\lib.win-amd64-3.8\\Box2D\n",
      "    copying library\\Box2D\\__init__.py -> build\\lib.win-amd64-3.8\\Box2D\n",
      "    creating build\\lib.win-amd64-3.8\\Box2D\\b2\n",
      "    copying library\\Box2D\\b2\\__init__.py -> build\\lib.win-amd64-3.8\\Box2D\\b2\n",
      "    running build_ext\n",
      "    building 'Box2D._Box2D' extension\n",
      "    swigging Box2D\\Box2D.i to Box2D\\Box2D_wrap.cpp\n",
      "    C:\\Users\\pinad\\anaconda3\\Scripts\\swig.exe -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library\\Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D\\Box2D_wrap.cpp Box2D\\Box2D.i\n",
      "    Box2D\\Common\\b2Math.h(67) : Warning 302: Identifier 'b2Vec2' redefined by %extend (ignored),\n",
      "    Box2D\\Box2D_math.i(47) : Warning 302: %extend definition of 'b2Vec2'.\n",
      "    Box2D\\Common\\b2Math.h(158) : Warning 302: Identifier 'b2Vec3' redefined by %extend (ignored),\n",
      "    Box2D\\Box2D_math.i(168) : Warning 302: %extend definition of 'b2Vec3'.\n",
      "    Box2D\\Common\\b2Math.h(197) : Warning 302: Identifier 'b2Mat22' redefined by %extend (ignored),\n",
      "    Box2D\\Box2D_math.i(301) : Warning 302: %extend definition of 'b2Mat22'.\n",
      "    Box2D\\Common\\b2Math.h(271) : Warning 302: Identifier 'b2Mat33' redefined by %extend (ignored),\n",
      "    Box2D\\Box2D_math.i(372) : Warning 302: %extend definition of 'b2Mat33'.\n",
      "    Box2D\\Collision\\b2DynamicTree.h(44) : Warning 312: Nested union not currently supported (ignored).\n",
      "    Box2D\\Common\\b2Settings.h(144) : Warning 506: Can't wrap varargs with keyword arguments enabled\n",
      "    Box2D\\Common\\b2Math.h(91) : Warning 509: Overloaded method b2Vec2::operator ()(int32) effectively ignored,\n",
      "    Box2D\\Common\\b2Math.h(85) : Warning 509: as it is shadowed by b2Vec2::operator ()(int32) const.\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\pinad\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\pinad\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dcr_n5jt\\\\box2d-py\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\pinad\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dcr_n5jt\\\\box2d-py\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\pinad\\AppData\\Local\\Temp\\pip-record-d936to6t\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\pinad\\anaconda3\\Include\\box2d-py' Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: baselines in c:\\users\\pinad\\anaconda3\\lib\\site-packages (0.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# !apt update\n",
    "!apt install -y python-opengl ffmpeg > /dev/null 2>&1\n",
    "# !apt install -y xvfb\n",
    "%pip install pyvirtualdisplay gym[atari] gym[box2d] gym[classic_control]\n",
    "# WORKAROUND: retry ---v\n",
    "%pip install gym[box2d]\n",
    "%pip install --no-deps baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglegym'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cf411a87ec7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkagglegym\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kagglegym'"
     ]
    }
   ],
   "source": [
    "import kagglegym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação e exploração do conjunto de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cálculos matemáticos\n",
    "import math\n",
    "\n",
    "# Plotagem de gráficos\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imputação de valores nulos\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Converter variáveis categóricas em números\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Seleção de variáveis\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Dividir dados de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Buscar os melhores parâmetros que serão utilizados nos modelos preditivos\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Algoritmos de Regressão\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor, AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Métricas de avaliação dos modelos preditivos\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Carregar e salvar objetos Python em arquivos no disco\n",
    "import pickle\n",
    "\n",
    "# Esse módulo ignara os avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 - Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando os dados \n",
    "df = pd.read_excel('Dados/Electric-cars/FEV-data-Excel.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando a variável alvo\n",
    "variavelAlvo = \"mean - Energy consumption [kWh/100 km]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo colunas desnecessárias\n",
    "df.drop([\"Car full name\", 'Make', 'Model'], axis=1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Reservar linhas para validar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma amostra do conjuto de dados\n",
    "# O parâmetro \"n\" define a quantidade de linhas da amostra\n",
    "dfValidacao = df.sample(n=1, random_state=1)\n",
    "dfValidacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo do DataFrame original as linhas que serão utilizadas para validar o modelo \n",
    "for k in dfValidacao.index:\n",
    "    df.drop([k], inplace = True)\n",
    "\n",
    "# É importante reiniciar os índices após a exclusão de linhas\n",
    "df.reset_index(inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo coluna\n",
    "df.drop([\"index\"], axis=1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Explorando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 - Informações sobre o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando informações sobre o dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Tratando valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores nulos por coluna\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto do tipo SimpleImputer com a média como estratégia  \n",
    "imputeMedia = SimpleImputer(missing_values=np.nan, strategy= \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o objeto do tipo SimpleImputer, substitui os valores nulos pela média em cada coluna com valor NA\n",
    "for k in df.columns[0:22]:\n",
    "    \n",
    "    # Verifica se a coluna possui valores nulos e se os valores não são do tipo texto\n",
    "    if df[k].isnull().sum() > 0 and df[k].dtype != object:\n",
    "        \n",
    "        # Realiza a imputação nos dados nulos\n",
    "        df[k] = imputeMedia.fit_transform(df[k].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores nulos por coluna\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os valores de uma coluna\n",
    "df[\"Type of brakes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o valor que desejamos inserir\n",
    "n = \"disc (front + rear)\"\n",
    "\n",
    "# Substitui todos os valores nulos da coluna pelo valor de n\n",
    "df[\"Type of brakes\"] = df[\"Type of brakes\"].fillna(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se há valores nulos na coluna\n",
    "df[\"Type of brakes\"].isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Tratando dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem dados duplicados.\n",
    "# Ocorrem dados duplicados quando uma linha inteira, é igual a outra\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 - Tratando valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores únicos\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Análise descritiva dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1 - Parâmetros dos gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a paleta de cores\n",
    "sns.color_palette(\"pastel\")\n",
    "\n",
    "# Define o tema utilizado.\n",
    "sns.set_theme(style=\"dark\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2 - Funções para desenhar os gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### a) Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um histograma\n",
    "def desenhaHistograma(coluna, variavelAnalisada):\n",
    "\n",
    "    # Calculando a quantidade de classes da variável analisada\n",
    "    n = coluna.count()\n",
    "    k = round(1+3.3*math.log10(n))\n",
    "   \n",
    "    # Calculando o intervalo de cada classe\n",
    "    frequencias, intervalos = np.histogram(coluna, bins = k)\n",
    "\n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.histplot(coluna, bins=k, kde=True)\n",
    "    ax.set_title(\"Histograma da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.set_xlabel(variavelAnalisada, fontsize = 12)\n",
    "    ax.set_ylabel(\"Frequência\", fontsize = 12)\n",
    "    ax.set_xticks(intervalos) \n",
    "    ax.bar_label(ax.containers[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b) Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um Boxplot\n",
    "def desenhaBoxplot(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.boxplot(data=coluna)\n",
    "    ax.set_title(\"Boxplot da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.set_xticklabels([variavelAnalisada]) # exibe o nome da variável\n",
    "    larguraBox = 0.63\n",
    "    i=0\n",
    "\n",
    "    # calcula o primeiro quartil (q1), o segundo (q2) e o terceiro quartil (q3)\n",
    "    q1, q2, q3 = coluna.quantile(0.25), coluna.quantile(0.5), coluna.quantile(0.75)\n",
    "    \n",
    "    # Lista com os quartis\n",
    "    quartis = [q1, q2, q3]\n",
    "\n",
    "    # Exibe os quartis no gráfico\n",
    "    for q in quartis:\n",
    "        x = i-larguraBox/2\n",
    "        y = q\n",
    "        ax.annotate('%.2f' % q, (x,y),\n",
    "                    xytext=(x-0.1, y), textcoords='data',\n",
    "                    va='center', ha='right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### c) Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um Scatter Plot\n",
    "def desenhaScatterPlot(colunaX, colunaY, variavelAnalisadaX, variavelAnalisadaY):\n",
    "    \n",
    "    # Cria o gráfico definido pelos valores do eixo x e do eixo y respectivamente.\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.scatterplot(x=colunaX, y=colunaY) \n",
    "    ax.set_title(\"Relação da variável \" + variavelAnalisadaX + \" com a variável \" + variavelAnalisadaY, fontsize = 16)\n",
    "    ax.set_xlabel(variavelAnalisadaX, fontsize = 12)\n",
    "    ax.set_ylabel(variavelAnalisadaY, fontsize = 12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### d) Gráfico de Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um gráfico de pizza\n",
    "def desenhaPizza(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Calculando o percentual\n",
    "    percentuais = round((coluna.value_counts()/coluna.value_counts().sum())*100, 2)\n",
    "\n",
    "    # Nome das categorias\n",
    "    nomeDasCategorias = coluna.value_counts().index\n",
    "\n",
    "    # Desenhando o gráfico\n",
    "    fig, ax = plt.subplots(figsize=(13, 6))\n",
    "    ax.pie(percentuais, labels=nomeDasCategorias, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    ax.set_title(\"Percentuais da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.legend(title=variavelAnalisada,loc=\"center left\",bbox_to_anchor=(1., 0., 0.5, 1.))\n",
    "    ax.axis('equal') # Garante que o gráfico seja desenhado no formato de círculo.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### d) Countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um gráfico Countplot\n",
    "def desenhaCountPlot(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.countplot(x=coluna, palette=(\"Pastel1\"), order = coluna.value_counts().index)\n",
    "    ax.set_title(\"Frequência absoluta da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.bar_label(ax.containers[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.3 Análise descritiva das variáveis quantitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "for k in df.columns[0:22]:\n",
    "    # Verifica se a coluna não possui valores do tipo texto\n",
    "    if df[k].dtypes != object:\n",
    "        \n",
    "        # Sumário estatístico\n",
    "        print(\"Resumo estatístico da variável \" + k + \"\\n\", df[k].describe())\n",
    "        \n",
    "        # Histograma\n",
    "        desenhaHistograma(df[k], k)\n",
    "        \n",
    "        # Boxplot\n",
    "        desenhaBoxplot(df[k], k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.4 Análise descritiva das variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "for k in df.columns[0:22]:\n",
    "    # Verifica se a coluna possui valores do tipo texto\n",
    "    if df[k].dtypes == object:\n",
    "        \n",
    "        # Frequência absoluta \n",
    "        desenhaCountPlot(df[k], k)\n",
    "        \n",
    "        # Percentuais\n",
    "        desenhaPizza(df[k], k)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.4.1 Análise descritiva da variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "pd.DataFrame(df[variavelAlvo].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequência absoluta \n",
    "desenhaHistograma(df[variavelAlvo], variavelAlvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentuais\n",
    "desenhaBoxplot(df[variavelAlvo], variavelAlvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.5 - Correlação entre as variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.5.1 - Matriz de correlação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a correlação \n",
    "correlacao = df.corr()\n",
    "\n",
    "# Criando uma máscara\n",
    "mascara = np.zeros_like(correlacao)\n",
    "\n",
    "# Selecionando a matriz triangular inferior da máscara.\n",
    "mascara[np.triu_indices_from(mascara)] = True\n",
    "\n",
    "# Cria a matriz de correlação\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "sns.heatmap(data = correlacao,\n",
    "            mask = mascara,\n",
    "            annot = True,\n",
    "            fmt = '.2f',\n",
    "            cmap='Blues',\n",
    "\n",
    "            )\n",
    "plt.title('Matriz de correlação', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.5.2 - Correlação entre a variável Wheelbase e a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScatterPlot\n",
    "desenhaScatterPlot(df[\"Wheelbase [cm]\"], df[variavelAlvo], \"Wheelbase [cm]\", variavelAlvo )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.5.3 - Correlação entre a variável Permissable gross weight [kg] e a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScatterPlot\n",
    "desenhaScatterPlot(df[\"Permissable gross weight [kg]\"], df[variavelAlvo], \"Permissable gross weight [kg]\", variavelAlvo )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Transformando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz uma cópia do dataframe\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tratando valores iguais a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as colunas que possuem valores iguais a zero\n",
    "# Loop que percorre todas as colunas\n",
    "# A notação de slicing [0:13] é para não incluir a variável alvo, porque apesar de ter números, a variável alvo é categórica\n",
    "for k in df2.columns[0:13]:\n",
    "    \n",
    "    # Verifica se os valores não são do tipo texto\n",
    "    if df2[k].dtype != object:\n",
    "        \n",
    "        # Imprime na tela a quantidade de valores iguais a zero existentes na coluna\n",
    "        print(k + \":\", len(df2[df2[k] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Convertendo variáveis categóricas em números"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Convertendo as variáveis preditoras de texto para número"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6aba3afff9ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Verificando o tipo de dados das colunas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "# Verificando o tipo de dados das colunas\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.2.1 Encoding com o Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.get_dummies(df2)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o nome das colunas\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizando o dataframe\n",
    "valoresVariavelAlvo = df3[variavelAlvo]\n",
    "df3.drop([variavelAlvo],  axis=1, inplace = True)\n",
    "\n",
    "# Atualizando a variável alvo\n",
    "df3[variavelAlvo] = valoresVariavelAlvo\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Dividindo os dados em treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATENÇÃO!! Qual o dataframe será utilizado df2 ou df3 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo uma cópia do dataframa\n",
    "dfDados = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(dfDados)\n",
    "numeroVariaveisPreditoras = len(dfDados.columns)-1\n",
    "\n",
    "# A notação de slicing [0:numeroVariaveisPreditoras] é para não incluir a variável alvo\n",
    "X = dfDados[dfDados.columns[0:numeroVariaveisPreditoras]].values.reshape((numeroObservacoes, numeroVariaveisPreditoras)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = dfDados[variavelAlvo].values # y pode ser um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisa os melhores valores para o parâmetro random_state\n",
    "# Array de valores para random_state de 1 até 200\n",
    "arrayRandomStates = np.arange(start=1, stop=200)\n",
    "\n",
    "# Cria uma lista vazia para armazenar os acertos\n",
    "listaR2 = []\n",
    "\n",
    "# Loop que percorre todos os valores da arrayRandomStates\n",
    "for k in arrayRandomStates:\n",
    "    Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=k)\n",
    "    modelo = XGBRegressor()# LinearRegression()\n",
    "    modelo.fit(Xtreino, Ytreino)\n",
    "    previsoes = modelo.predict(Xteste)\n",
    "    listaR2.append(round(r2_score(Yteste, previsoes)*100,2))\n",
    "    \n",
    "# Exibe os melhores valores para o random_state\n",
    "resultados = pd.DataFrame({'random_state':arrayRandomStates, \n",
    "                           'R2':listaR2})\n",
    "melhorRandomState = resultados[resultados['R2'] == resultados['R2'].max()]\n",
    "melhorRandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide os dados em treino e teste\n",
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=int(melhorRandomState[\"random_state\"][0:1].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Seleção de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando a biblioteca mlxtend\n",
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a classe SequentialFeatureSelector da biblioteca mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um objeto da classe SFS para selecionar as melhores variáveis preditoras conforme R2, utilizando o algoritmo XGBRegressor.\n",
    "sfs = SFS (\n",
    "    estimator  = XGBRegressor(), \n",
    "    k_features = numeroVariaveisPreditoras,\n",
    "    forward    = True, \n",
    "    floating   = False, \n",
    "    scoring    = 'r2',\n",
    "    cv         = 3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo os valores de X para DataFrame. Isso facilita para retornar o nome das variáveis\n",
    "dfX = pd.DataFrame(X, columns=dfDados.columns[0:numeroVariaveisPreditoras])\n",
    "\n",
    "# Convertendo os valores de y para um objeto do tipo Series do Pandas\n",
    "y_series = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisando as melhores variáveis preditoras.\n",
    "sfs = sfs.fit(\n",
    "    X = dfX, \n",
    "    y = y_series,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo o resultado da pesquisa das melhores variáveis para um dataframe.\n",
    "# O método \"T\" transforma linhas em colunas e colunas em linhas\n",
    "dfSelecaoVariaveis = pd.DataFrame(sfs.subsets_).T\n",
    "dfSelecaoVariaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a coluna \"avg_score\" para o tipo float\n",
    "dfSelecaoVariaveis.avg_score = dfSelecaoVariaveis.avg_score.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena o dataframe de acordo a variável \"avg_score\" do maior para o menor\n",
    "dfSelecaoVariaveis.sort_values(by=[\"avg_score\"], ascending=False, inplace=True)\n",
    "dfSelecaoVariaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolhendo as melhores variáveis\n",
    "melhoresVariaveis = dfSelecaoVariaveis.iloc[0,3]\n",
    "melhoresVariaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo a Tupla para uma lista\n",
    "variaveisSelecionadas = list(melhoresVariaveis)\n",
    "variaveisSelecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Dividindo os dados de treino e teste com as variáveis selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(dfDados)\n",
    "numeroVariaveisPreditoras = len(variaveisSelecionadas)\n",
    "X = dfDados[variaveisSelecionadas].values.reshape((numeroObservacoes, numeroVariaveisPreditoras)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = dfDados[variavelAlvo].values # y pode ser um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisa os melhores valores para o parâmetro random_state\n",
    "# Array de valores para random_state de 1 até 100\n",
    "arrayRandomStates = np.arange(start=1, stop=200)\n",
    "\n",
    "# Cria uma lista vazia para armazenar os acertos\n",
    "listaR2 = []\n",
    "\n",
    "# Loop que percorre todos os valores da arrayRandomStates\n",
    "for k in arrayRandomStates:\n",
    "    Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=k)\n",
    "    modelo = XGBRegressor()\n",
    "    modelo.fit(Xtreino, Ytreino)\n",
    "    previsoes = modelo.predict(Xteste)\n",
    "    listaR2.append(round(r2_score(Yteste, previsoes)*100,2))\n",
    "    \n",
    "# Exibe os melhores valores para o random_state\n",
    "resultados = pd.DataFrame({'random_state':arrayRandomStates, \n",
    "                           'R2':listaR2})\n",
    "melhorRandomState = resultados[resultados['R2'] == resultados['R2'].max()]\n",
    "melhorRandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide os dados em treino e teste\n",
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=int(melhorRandomState[\"random_state\"][0:1].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaCrossValidation(dadosEntrada):\n",
    "    # Criando uma lista vazia para armazenar os modelos de Machine Learning\n",
    "    modelos = []\n",
    "\n",
    "    # Criando um Dataframe para armazenar a média e o desvio-padrão de cada um dos algoritmos testados.\n",
    "    dfMedias   = pd.DataFrame(columns = ['Algoritmo', 'Media'])\n",
    "\n",
    "    # Define a quantidade de folds\n",
    "    numeroFolds = 5\n",
    "\n",
    "    # Define a semente para criar os folds\n",
    "    seed = 15\n",
    "\n",
    "    # KFold divide o conjunto de dados em grupos de amostras, chamados folds\n",
    "    kfold = KFold(n_splits = numeroFolds, shuffle=True, random_state = seed)\n",
    "\n",
    "    # Adicionando os modelos a lista\n",
    "    modelos.append((\"Regressão Linear\", LinearRegression()))\n",
    "    modelos.append((\"Ridge\", Ridge()))\n",
    "    modelos.append((\"KNN\", KNeighborsRegressor()))\n",
    "    modelos.append((\"SVM\", LinearSVR()))\n",
    "    modelos.append((\"Árvore de Decisão\", DecisionTreeRegressor()))\n",
    "    modelos.append((\"Random Forest\", RandomForestRegressor()))\n",
    "    modelos.append((\"Extra Tree\", ExtraTreesRegressor()))\n",
    "    modelos.append((\"Bagging\", BaggingRegressor()))\n",
    "    modelos.append((\"AdaBoost\", AdaBoostRegressor()))\n",
    "    modelos.append((\"Voting\", VotingRegressor(estimators=[(\"AD\",DecisionTreeRegressor()),(\"GB\", GradientBoostingRegressor()),(\"RL\", LinearRegression())])))\n",
    "    modelos.append((\"Gradient Boosting\", GradientBoostingRegressor()))\n",
    "    modelos.append((\"XGBoost\", XGBRegressor()))\n",
    "\n",
    "    for nome, modelo in modelos:\n",
    "        # Cross Validation\n",
    "        resultados = cross_val_score(modelo, dadosEntrada, y, cv=kfold, scoring=\"r2\")\n",
    "\n",
    "        # Calcula a média dos resultados\n",
    "        media = resultados.mean()*100\n",
    "\n",
    "        # Define os parâmetros para adicionar a linha no dataframe\n",
    "        novaLinha = {\"Algoritmo\": nome,\n",
    "                     \"Media\": media}\n",
    "\n",
    "        # Adiciona uma linha ao dataframe\n",
    "        dfMedias = dfMedias.append(novaLinha, ignore_index=True)\n",
    "\n",
    "    # Ordena o dataframe da maior média para a menor    \n",
    "    dfMedias.sort_values(by=[\"Media\"], ascending=False, inplace=True)\n",
    "    return dfMedias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 - Cross Validation com dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 - Cross Validation com dados normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto da classe MinMaxScaler \n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de entrada\n",
    "xNormalizado = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(xNormalizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 - Cross Validation com dados padronizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto StandardScaler, calcula a média e o desvio-padrão que serão usados para padronizar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de entrada\n",
    "xPadronizado = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(xPadronizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Preparando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 - Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto da classe MinMaxScaler \n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de  Xtreino\n",
    "XtreinoNormalizados = min_max_scaler.fit_transform(Xtreino)\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de Xteste\n",
    "XtesteNormalizados = min_max_scaler.fit_transform(Xteste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 - Padronizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto StandardScaler, calcula a média e o desvio-padrão que serão usados para padronizar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de Xtreino\n",
    "XtreinoPadronizados = scaler.fit_transform(Xtreino)\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de Xteste\n",
    "XtestePadronizados = scaler.fit_transform(Xteste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 - Selecionando a apresentação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os dados podem estar com apresentação \"Originais\", \"Normalizados\" ou \"Padronizados\"\n",
    "apresentacaoDosDados = \"Originais\"\n",
    "\n",
    "if apresentacaoDosDados == \"Originais\":\n",
    "    dadosXtreino = Xtreino\n",
    "    dadosXteste = Xteste\n",
    "elif apresentacaoDosDados == \"Normalizados\":\n",
    "    dadosXtreino = XtreinoNormalizados\n",
    "    dadosXteste = XtesteNormalizados\n",
    "else:\n",
    "    dadosXtreino = XtreinoPadronizados\n",
    "    dadosXteste = XtestePadronizados\n",
    "\n",
    "print(\"Os dados estão com a seguinte apresentação:\", apresentacaoDosDados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Criando os modelos de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame para comparar a acurácia de cada algoritmo\n",
    "# DataFrame para comparar a R2 de cada algoritmo\n",
    "comparaAlgoritmo = {\"Algoritmo\": [\"Gradient Tree Boosting\", \"XGBRegressor\", \"Random Forest\"],\n",
    "                   \"R2\": [\"-\", \"-\", \"-\"],\n",
    "                   \"Mean Squared Error\": [\"-\", \"-\", \"-\"]\n",
    "                   }\n",
    "dfComparaAlgoritmo = pd.DataFrame(comparaAlgoritmo)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.11 - Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "gradientBoostingRegressor = GradientBoostingRegressor()\n",
    "\n",
    "# Treinamento do modelo\n",
    "gradientBoostingRegressor.fit(dadosXtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = gradientBoostingRegressor.predict(dadosXteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Mean Squared Error\n",
    "mse = mean_squared_error(Yteste, previsoes)\n",
    "print(\"Erro do modelo: %.2f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[0,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[0,2] =  round(mse,2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.12 - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Treinamento do modelo\n",
    "xgb.fit(dadosXtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = xgb.predict(dadosXteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Mean Squared Error\n",
    "mse = mean_squared_error(Yteste, previsoes)\n",
    "print(\"Erro do modelo: %.2f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[1,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[1,2] =  round(mse, 2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando os melhores parâmetros segundo o RandomizedSearchCV\n",
    "# Criando o modelo\n",
    "randomForestRegressor = RandomForestRegressor(random_state=6)\n",
    "\n",
    "# Treinamento do modelo\n",
    "randomForestRegressor.fit(Xtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = randomForestRegressor.predict(Xteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Mean Squared Error\n",
    "mse = mean_squared_error(Yteste, previsoes)\n",
    "print(\"Erro do modelo: %.2f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[2,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[2,2] =  round(mse, 2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - Selecionando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena o DataFrame de acordo o valor do Mean Squared Error, em ordem crecente\n",
    "dfComparaAlgoritmo.sort_values(by=[\"Mean Squared Error\"], inplace=True)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o modelo final\n",
    "modeloFinal = xgb\n",
    "modeloFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 - Salvando e carregando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 - Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo\n",
    "arquivo = 'Dados/Electric-cars/modeloRegressorFinal.sav'\n",
    "pickle.dump(modeloFinal, open(arquivo, 'wb'))\n",
    "print(\"Modelo salvo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 - Carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo\n",
    "modeloRegressor = pickle.load(open(arquivo, 'rb'))\n",
    "print(\"Modelo carregado!\")\n",
    "modeloRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 - Salvando o objeto de normalização/padronização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os dados podem estar com apresentação \"Originais\", \"Normalizados\" ou \"Padronizados\"\n",
    "if apresentacaoDosDados == \"Normalizados\":\n",
    "    arquivoNormalizador = 'Dados/Electric-cars/normalizador.sav'\n",
    "    pickle.dump(min_max_scaler, open(arquivoNormalizador, 'wb'))\n",
    "    print(\"Normalizador salvo!\")\n",
    "elif apresentacaoDosDados == \"Padronizados\":\n",
    "    arquivoPadronizador = 'Dados/Electric-cars/padronizador.sav'\n",
    "    pickle.dump(scaler, open(arquivoPadronizador, 'wb'))\n",
    "    print(\"Padronizador salvo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 - Validando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o dataframe\n",
    "dfValidacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando variáveis dummies\n",
    "dfValidacao = pd.get_dummies(dfValidacao)\n",
    "dfValidacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as variáveis selecionadas\n",
    "variaveisSelecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando colunas ao dataframe\n",
    "dfValidacao['Drive type_2WD (front)'] = 0\n",
    "dfValidacao['Drive type_2WD (rear)'] = 0\n",
    "dfValidacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz as previsões dos novos dados\n",
    "\n",
    "if apresentacaoDosDados == \"Originais\":\n",
    "    novosDados = dfValidacao[variaveisSelecionadas].values\n",
    "    # Fazendo previsões\n",
    "    previsoes = modeloRegressor.predict(novosDados)\n",
    "\n",
    "elif apresentacaoDosDados == \"Normalizados\":\n",
    "    # Carregando o objeto de normalização dos dados\n",
    "    normalizador = pickle.load(open(arquivoNormalizador, 'rb'))\n",
    "    # Normalizando os novos dados\n",
    "    novosDados = dfValidacao[variaveisSelecionadas].values\n",
    "    novosDadosNormalizados = normalizador.transform(novosDados)\n",
    "    previsoes = modeloRegressor.predict(novosDadosNormalizados)\n",
    "\n",
    "else:\n",
    "    # Carregando o objeto de padronização dos dados\n",
    "    padronizador = pickle.load(open(arquivoPadronizador, 'rb'))\n",
    "    # Padronizando os novos dados\n",
    "    novosDados = dfValidacao[variaveisSelecionadas].values\n",
    "    novosDadosPadronizados = padronizador.transform(novosDados)\n",
    "    # Fazendo previsões\n",
    "    previsoes = modeloRegressor.predict(novosDadosPadronizados)\n",
    "\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
