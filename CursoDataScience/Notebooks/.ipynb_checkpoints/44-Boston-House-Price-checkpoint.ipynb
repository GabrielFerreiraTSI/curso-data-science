{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Boston House-Price Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Python Version:', python_version())\n",
    "\n",
    "# Verificando as versões dos pacotes instalados\n",
    "pandasVersion = !pip show pandas\n",
    "matplotlibVersion = !pip show matplotlib\n",
    "sklearnVersion = !pip show scikit-learn\n",
    "print('Pandas', pandasVersion[1])\n",
    "print(\"Matplotlib\", matplotlibVersion[1])\n",
    "print(\"Sklearn\", sklearnVersion[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Definição do Problema de Negócio\n",
    "<details>\n",
    "    <summary>\n",
    "        <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>&nbsp;&nbsp;Clique para mais detalhes</a>\n",
    "    </summary>\n",
    "    <br>\n",
    "\n",
    "Boston House-Price Dataset contém informações coletadas pelo Serviço de Censo dos EUA sobre moradias na área de Massachusetts Mass. Este conjunto de dados é amplamente utilizado por iniciantes em Machine Learning. O dataset é pequeno, com apenas 506 registros. \n",
    "\n",
    "O objetivo é prever os preços de casas em Boston a partir das informações fornecidas pelo conjunto de dados. Por essa razão, estamos diante de um problema de regressão. <br>\n",
    "    \n",
    "Descrição das variáveis:<br>\n",
    "- **crim**: é a taxa de criminalidade per capita na área do imóvel;<br>\n",
    "- **zn**: é a proporção de terrenos residenciais divididos por lotes acima de 25.000 pés quadrados;<br>\n",
    "- **indus**: é a proporção de acres não comerciais na área do imóvel;<br>\n",
    "- **chas**: se a casa limita ou não o Rio Charles (1 se o trecho limita o rio; 0 caso contrário);<br>\n",
    "- **nox**: é a concentração de óxidos nítricos (partes por 10 milhões);<br>\n",
    "- **rm**: é o número médio de quartos por habitação;<br>\n",
    "- **age**: é a proporção de unidades ocupadas pelos proprietários construídas antes de 1940;<br>\n",
    "- **dis**: é a distância ponderada de cinco centros de trabalho em Boston;<br>\n",
    "- **rad**: é o índice de acessibilidade às rodovias radiais;<br>\n",
    "- **tax**: é a taxa de imposto sobre a propriedade em US 10.000;<br>\n",
    "- **ptratio**: é a proporção aluno-professor na área do imóvel;<br>\n",
    "- **bk**: é um cálculo referente a esta equação 1000 (Bk - 0,63) ^ 2;<br>\n",
    "- **lstat**: é a porcentagem da população de baixa renda e;<br>\n",
    "- **medv (variável alvo)**: é a mediana do valor das casas ocupadas pelos proprietários em US 1.000.<br>\n",
    "    \n",
    "Endereço do conjunto de dados: https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset/input<br>\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 - Coletando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação e exploração do conjunto de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cálculos matemáticos\n",
    "import math\n",
    "\n",
    "# Plotagem de gráficos\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imputação de valores nulos\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Converter variáveis categóricas em números\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Seleção de variáveis\n",
    "from sklearn.feature_selection import RFE, SelectKBest\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Dividir dados de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Buscar os melhores parâmetros que serão utilizados nos modelos preditivos\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Algoritmos de Regressão\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor, AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Métricas de avaliação dos modelos preditivos\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Carregar e salvar objetos Python em arquivos no disco\n",
    "import pickle\n",
    "\n",
    "# Esse módulo ignara os avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 - Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando os dados \n",
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'BK', 'LSTAT', 'MEDV']\n",
    "df = pd.read_csv('Dados/Boston-Housing/housing.csv', sep=r\"\\s+\", names=colunas)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando a variável alvo\n",
    "variavelAlvo = \"MEDV\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Reservar linhas para validar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma amostra do conjuto de dados\n",
    "# O parâmetro \"n\" define a quantidade de linhas da amostra\n",
    "dfValidacao = df.sample(n=2, random_state=1)\n",
    "dfValidacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo do DataFrame original as linhas que serão utilizadas para validar o modelo \n",
    "for k in dfValidacao.index:\n",
    "    df.drop([k], inplace = True)\n",
    "\n",
    "# É importante reiniciar os índices após a exclusão de linhas\n",
    "df.reset_index(inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo coluna\n",
    "df.drop([\"index\"], axis=1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Explorando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 - Informações sobre o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando informações sobre o dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Tratando valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores nulos por coluna\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 - Tratando dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem dados duplicados.\n",
    "# Ocorrem dados duplicados quando uma linha inteira, é igual a outra\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Excluindo as linhas duplicadas mantendo a primeira ocorrência da linha\n",
    "df.drop_duplicates(ignore_index=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 - Tratando valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores únicos\n",
    "# Variáveis quantitativas com muitos valores únicos podem prejudicar o aprendizado de máquina\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 - Análise descritiva dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.1 - Parâmetros dos gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a paleta de cores\n",
    "sns.color_palette(\"pastel\")\n",
    "\n",
    "# Define o tema utilizado.\n",
    "sns.set_theme(style=\"darkgrid\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.2 - Funções para desenhar os gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### a) Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um histograma\n",
    "def desenhaHistograma(coluna, variavelAnalisada):\n",
    "\n",
    "    # Calculando a quantidade de classes da variável analisada\n",
    "    n = coluna.count()\n",
    "    k = round(1+3.3*math.log10(n))\n",
    "   \n",
    "    # Calculando o intervalo de cada classe\n",
    "    frequencias, intervalos = np.histogram(coluna, bins = k)\n",
    "\n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.histplot(coluna, bins=k, kde=True)\n",
    "    ax.set_title(\"Histograma da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.set_xlabel(variavelAnalisada, fontsize = 12)\n",
    "    ax.set_ylabel(\"Frequência\", fontsize = 12)\n",
    "    ax.set_xticks(intervalos) \n",
    "    for barras in ax.containers:\n",
    "        ax.bar_label(barras)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b) Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um Boxplot\n",
    "def desenhaBoxplot(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.boxplot(data=coluna)\n",
    "    ax.set_title(\"Boxplot da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.set_xticklabels([variavelAnalisada]) # exibe o nome da variável\n",
    "    larguraBox = 0.63\n",
    "    i=0\n",
    "\n",
    "    # calcula o primeiro quartil (q1), o segundo (q2) e o terceiro quartil (q3)\n",
    "    q1, q2, q3 = coluna.quantile(0.25), coluna.quantile(0.5), coluna.quantile(0.75)\n",
    "    \n",
    "    # Lista com os quartis\n",
    "    quartis = [q1, q2, q3]\n",
    "\n",
    "    # Exibe os quartis no gráfico\n",
    "    for q in quartis:\n",
    "        x = i-larguraBox/2\n",
    "        y = q\n",
    "        ax.annotate('%.2f' % q, (x,y),\n",
    "                    xytext=(x-0.1, y), textcoords='data',\n",
    "                    va='center', ha='right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### c) Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um Scatter Plot\n",
    "def desenhaScatterPlot(colunaX, colunaY, variavelAnalisadaX, variavelAnalisadaY):\n",
    "    \n",
    "    # Cria o gráfico definido pelos valores do eixo x e do eixo y respectivamente.\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.scatterplot(x=colunaX, y=colunaY) \n",
    "    ax.set_title(\"Relação da variável \" + variavelAnalisadaX + \" com a variável \" + variavelAnalisadaY, fontsize = 16)\n",
    "    ax.set_xlabel(variavelAnalisadaX, fontsize = 12)\n",
    "    ax.set_ylabel(variavelAnalisadaY, fontsize = 12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### d) CountPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um gráfico Countplot\n",
    "def desenhaCountPlot(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.countplot(x=coluna, palette=(\"Pastel1\"),  order = coluna.value_counts().index)\n",
    "    ax.set_title(\"Frequência absoluta da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    for barras in ax.containers:\n",
    "        ax.bar_label(barras)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### e) Gráfico de Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um gráfico de pizza\n",
    "def desenhaPizza(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Calculando o percentual\n",
    "    percentuais = round((coluna.value_counts()/coluna.value_counts().sum())*100, 2)\n",
    "\n",
    "    # Nome das categorias\n",
    "    nomeDasCategorias = coluna.value_counts().index\n",
    "\n",
    "    # Desenhando o gráfico\n",
    "    fig, ax = plt.subplots(figsize=(13, 6))\n",
    "    ax.pie(percentuais, labels=nomeDasCategorias, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    ax.set_title(\"Percentuais da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.legend(title=variavelAnalisada,loc=\"center left\",bbox_to_anchor=(1., 0., 0.5, 1.))\n",
    "    ax.axis('equal') # Garante que o gráfico seja desenhado no formato de círculo.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.3 Análise descritiva das variáveis quantitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "# A notação de slicing [0:13] é para não incluir a variável alvo\n",
    "for k in df.columns[0:13]:\n",
    "    # Verifica se a coluna não possui valores do tipo texto\n",
    "    if df[k].dtypes != object:\n",
    "        \n",
    "        # Sumário estatístico\n",
    "        print(\"Resumo estatístico da variável \" + k + \"\\n\", df[k].describe())\n",
    "        \n",
    "        # Histograma\n",
    "        desenhaHistograma(df[k], k)\n",
    "        \n",
    "        # Boxplot\n",
    "        desenhaBoxplot(df[k], k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.4 Análise descritiva das variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "for k in df.columns[0:13]:\n",
    "    # Verifica se a coluna possui valores do tipo texto\n",
    "    if df[k].dtypes == object:\n",
    "        \n",
    "        # Frequência absoluta \n",
    "        desenhaCountPlot(df[k], k)\n",
    "        \n",
    "        # Percentuais\n",
    "        desenhaPizza(df[k], k)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountPlot da variável CHAS\n",
    "desenhaCountPlot(df.CHAS, \"CHAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de Pizza da variável CHAS\n",
    "desenhaPizza(df.CHAS, \"CHAS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.5 Análise descritiva da variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "pd.DataFrame(df[variavelAlvo].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequência absoluta \n",
    "desenhaHistograma(df[variavelAlvo], variavelAlvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentuais\n",
    "desenhaBoxplot(df[variavelAlvo], variavelAlvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5.6 - Correlação entre as variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.5.6.1 - Matriz de correlação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a correlação \n",
    "correlacao = df.corr()\n",
    "\n",
    "# Criando uma máscara\n",
    "mascara = np.zeros_like(correlacao)\n",
    "\n",
    "# Selecionando a matriz triangular inferior da máscara.\n",
    "mascara[np.triu_indices_from(mascara)] = True\n",
    "\n",
    "# Criando o heatmap\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "sns.heatmap(data = correlacao,\n",
    "            mask = mascara,\n",
    "            annot = True,\n",
    "            fmt = '.2f',\n",
    "            cmap='Blues',\n",
    "\n",
    "            )\n",
    "plt.title('Matriz de correlação', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.5.6.2 - Correlação entre a variável RM e a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScatterPlot\n",
    "desenhaScatterPlot(df.RM, df.MEDV, \"RM\",\"MEDV\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.5.6.3 - Correlação entre a variável LSTAT e a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScatterPlot\n",
    "desenhaScatterPlot(df.LSTAT, df.MEDV, \"LSTAT\",\"MEDV\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Transformando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz uma cópia do dataframe\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tratando valores iguais a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as colunas que possuem valores iguais a zero\n",
    "# Loop que percorre todas as colunas\n",
    "# A notação de slicing [0:13] é para não incluir a variável alvo, porque apesar de ter números, a variável alvo é categórica\n",
    "for k in df2.columns[0:13]:\n",
    "    \n",
    "    # Verifica se os valores não são do tipo texto\n",
    "    if df2[k].dtype != object:\n",
    "        \n",
    "        # Imprime na tela a quantidade de valores iguais a zero existentes na coluna\n",
    "        print(k + \":\", len(df2[df2[k] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Identificando e tratando valores outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "# A notação de slicing [0:13] é para não incluir a variável alvo, porque apesar de ter números, a variável alvo é categórica\n",
    "for k in df.columns[0:13]:\n",
    "    \n",
    "    # Verifica se os valores da coluna não são do tipo texto\n",
    "    if df2[k].dtype != object:\n",
    "       \n",
    "        # Calculando o zscore da coluna\n",
    "        zscore = (df2[k] - df2[k].mean()) / df2[k].std()\n",
    "        \n",
    "        # Pesquisando valores menores que -3 ou maiores que 3 que são considerados outliers\n",
    "        outliers = zscore[(zscore < -3) | (zscore > 3)]\n",
    "        \n",
    "        # Calculando o limite superior\n",
    "        limiteSuperior = df2[k].mean() + 3 * df2[k].std()\n",
    "\n",
    "        # Calculando o limite inferior\n",
    "        limiteInferior = df2[k].mean() - 3 * df2[k].std()\n",
    "        \n",
    "        # Verifica se há outliers na coluna \n",
    "        if len(outliers) > 0:\n",
    "            \n",
    "            # Calcula a média da coluna, excluindo os valores outliers\n",
    "            media = df2[k][(df[k] > limiteInferior) & (df2[k] <= limiteSuperior)].mean()\n",
    "            \n",
    "            # Cria uma lista vazia para armazenar as linhas com outliers\n",
    "            linhasComOutlier = []\n",
    "             \n",
    "            # Loop que percorre as linhas com outliers\n",
    "            for j in outliers.index:\n",
    "                \n",
    "                # Substitui a célula com valor outlier pela média\n",
    "                df2[k] = df2[k].replace(df2.iloc[j][k], media)\n",
    "                \n",
    "                # Adiciona o índice da linha na lista\n",
    "                linhasComOutlier.append(j)\n",
    "                \n",
    "            print(\"- Quantidade de valores outliers \" + \"da variável \" + k + \" substituídos pela média\"  + \":\", len(outliers))\n",
    "            print(\"- Linha (as) da variável \" + k + \" que foi (foram) alterada (as):\", linhasComOutlier)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Convertendo variáveis categóricas em números"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Convertendo as variáveis preditoras de texto para número"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2.1 Encoding com o Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3 = pd.get_dummies(df2)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizando o nome das colunas\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Organizando o dataframe\n",
    "valoresVariavelAlvo = df3[variavelAlvo]\n",
    "df3.drop([variavelAlvo],  axis=1, inplace = True)\n",
    "\n",
    "# Atualizando a variável alvo\n",
    "df3[variavelAlvo] = valoresVariavelAlvo\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Dividindo os dados em treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATENÇÃO!! Qual o dataframe será utilizado df2 ou df3 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo uma cópia do dataframa\n",
    "dfDados = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(dfDados)\n",
    "numeroVariaveisPreditoras = len(dfDados.columns)-1\n",
    "\n",
    "# A notação de slicing [0:13] é para não incluir a variável alvo\n",
    "X = dfDados[dfDados.columns[0:13]].values.reshape((numeroObservacoes, numeroVariaveisPreditoras)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = dfDados[variavelAlvo].values # y pode ser um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisa os melhores valores para o parâmetro random_state\n",
    "# Array de valores para random_state de 1 até 200\n",
    "arrayRandomStates = np.arange(start=1, stop=200)\n",
    "\n",
    "# Cria uma lista vazia para armazenar os acertos\n",
    "listaR2 = []\n",
    "\n",
    "# Loop que percorre todos os valores da arrayRandomStates\n",
    "for k in arrayRandomStates:\n",
    "    Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=k)\n",
    "    modelo = XGBRegressor()\n",
    "    modelo.fit(Xtreino, Ytreino)\n",
    "    previsoes = modelo.predict(Xteste)\n",
    "    listaR2.append(round(r2_score(Yteste, previsoes)*100,2))\n",
    "    \n",
    "# Exibe os melhores valores para o random_state\n",
    "resultados = pd.DataFrame({'random_state':arrayRandomStates, \n",
    "                           'R2':listaR2})\n",
    "melhorRandomState = resultados[resultados['R2'] == resultados['R2'].max()]\n",
    "melhorRandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide os dados em treino e teste\n",
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=int(melhorRandomState[\"random_state\"][0:1].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Seleção de variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - Selecionado as melhores variáveis com o Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "randomForestRegressor = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Treinando o modelo\n",
    "randomForestRegressor.fit(X, y)\n",
    "\n",
    "# Atribuindo a importância das variáveis a uma Series do Pandas\n",
    "importanciaVariaveis = pd.Series(data = randomForestRegressor.feature_importances_, index = dfDados.columns[0:13])\n",
    "\n",
    "# Gráfico com a importância das variáveis\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "importanciaVariaveis.sort_values().plot.bar()\n",
    "plt.title(\"Níveis de importância das variáveis - Random Forest\", fontsize = 16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 - Selecionado as melhores variáveis com o SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria o objeto SelectKBest\n",
    "selectkBest = SelectKBest(k = 4)\n",
    "\n",
    "# Executa a função em (X, y) e obtém as variáveis selecionadas\n",
    "selectkBestTreinado = selectkBest.fit(X, y)\n",
    "\n",
    "# Atribuindo a importância das variáveis a uma Series do Pandas\n",
    "importanciaVariaveis = pd.Series(data = selectkBestTreinado.scores_, index = dfDados.columns[0:13])\n",
    "\n",
    "# Gráfico com a importância das variáveis\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "importanciaVariaveis.sort_values().plot.bar()\n",
    "plt.title(\"Níveis de importância das variáveis - SelectKBest\", fontsize = 16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 - Selecionado as melhores variáveis com Eliminação Recursiva de Atributos RFE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "extraTreesRegressor = ExtraTreesRegressor(random_state=0)\n",
    "\n",
    "# Treinando o modelo\n",
    "extraTreesRegressor.fit(X, y)\n",
    "\n",
    "# Criando Eliminação Recursiva de Atributos RFE\n",
    "eliminacaoRecursiva = RFE(extraTreesRegressor)\n",
    "\n",
    "# Treinando Eliminação Recursiva de Atributos RFE\n",
    "eliminacaoRecursivaTreinada = eliminacaoRecursiva.fit(X, y)\n",
    "\n",
    "# Gráfico com a importância das variáveis\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "plt.title(\"Importância das variáveis - RFE\", fontsize = 16)\n",
    "# A notação de slicing [0:13] é para não incluir a variável alvo\n",
    "plt.bar(dfDados.columns[0:13], eliminacaoRecursivaTreinada.support_)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Dividindo os dados de treino e teste com as variáveis selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variáveis selecionadas\n",
    "variaveisSelecionadas = [\"INDUS\", \"RM\", \"DIS\", \"TAX\", \"PTRATIO\", \"LSTAT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(dfDados)\n",
    "numeroVariaveisPreditoras = len(variaveisSelecionadas)\n",
    "X = dfDados[variaveisSelecionadas].values.reshape((numeroObservacoes, numeroVariaveisPreditoras)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = dfDados[variavelAlvo].values # y pode ser um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pesquisa os melhores valores para o parâmetro random_state\n",
    "# Array de valores para random_state de 1 até 100\n",
    "arrayRandomStates = np.arange(start=1, stop=200)\n",
    "\n",
    "# Cria uma lista vazia para armazenar os acertos\n",
    "listaR2 = []\n",
    "\n",
    "# Loop que percorre todos os valores da arrayRandomStates\n",
    "for k in arrayRandomStates:\n",
    "    Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=k)\n",
    "    modelo = XGBRegressor()\n",
    "    modelo.fit(Xtreino, Ytreino)\n",
    "    previsoes = modelo.predict(Xteste)\n",
    "    listaR2.append(round(r2_score(Yteste, previsoes)*100,2))\n",
    "    \n",
    "# Exibe os melhores valores para o random_state\n",
    "resultados = pd.DataFrame({'random_state':arrayRandomStates, \n",
    "                           'R2':listaR2})\n",
    "melhorRandomState = resultados[resultados['R2'] == resultados['R2'].max()]\n",
    "melhorRandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Divide os dados em treino e teste\n",
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=int(melhorRandomState[\"random_state\"][0:1].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Cross Validation\n",
    "<details>\n",
    "    <summary>\n",
    "        <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>&nbsp;&nbsp;Clique para mais detalhes</a>\n",
    "    </summary>\n",
    "    <br>\n",
    "\n",
    "Cross-validation é uma técnica comumente usada em machine learning para avaliar a capacidade de generalização de um modelo preditivo. Ela envolve a divisão dos dados disponíveis em vários conjuntos de treinamento e vários conjuntos de teste, permitindo que o modelo seja testado em dados independentes para verificar o desempenho e a capacidade de generalização.<br>\n",
    "\n",
    "O procedimento básico de cross-validation envolve dividir o conjunto de dados em k partes iguais (também conhecidas como \"folds\") de tamanho aproximadamente igual. Em seguida, o modelo é treinado em k-1 partes desses folds e avaliado no fold restante. Esse processo é repetido k vezes, alternando o fold de teste a cada iteração.\n",
    "\n",
    "Existem várias formas comuns de cross-validation, sendo a validação cruzada k-fold (k-fold cross-validation) a mais amplamente utilizada. Nessa abordagem, o conjunto de dados é dividido em k partes iguais, e o modelo é treinado e avaliado k vezes, utilizando cada parte como o conjunto de teste uma vez.\n",
    "\n",
    "Ao final do processo de cross-validation, são obtidas k medidas de desempenho do modelo, uma para cada iteração. Essas medidas podem ser resumidas para fornecer uma estimativa geral do desempenho do modelo, como a média ou a mediana das medidas obtidas.\n",
    "\n",
    "A utilização do cross-validation ajuda a mitigar o risco de overfitting (sobreajuste) do modelo aos dados de treinamento, fornecendo uma avaliação mais robusta do desempenho em dados não vistos. Isso é especialmente útil quando se tem um conjunto de dados pequeno, pois permite obter uma estimativa mais confiável do desempenho do modelo em geral.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a quantidade de folds\n",
    "numeroFolds = 5\n",
    "\n",
    "# Define a semente para criar os folds\n",
    "seed = 15\n",
    "\n",
    "# KFold divide o conjunto de dados em grupos de amostras, chamados folds\n",
    "kfold = KFold(n_splits = numeroFolds, shuffle=True, random_state = seed)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = XGBRegressor()\n",
    "\n",
    "# Cross Validation\n",
    "resultados = cross_val_score(modelo, X, y, cv=kfold, scoring=\"r2\")\n",
    "\n",
    "print(\"R2 encontrados:\", resultados*100)\n",
    "print(\"Média dos R2:\", resultados.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaCrossValidation(dadosEntrada, dadosSaida):\n",
    "    # Criando uma lista vazia para armazenar os modelos de Machine Learning\n",
    "    modelos = []\n",
    "    \n",
    "    # Adicionando os modelos a lista\n",
    "    modelos.append((\"Regressão Linear\", LinearRegression()))\n",
    "    modelos.append((\"Ridge\", Ridge()))\n",
    "    modelos.append((\"KNN\", KNeighborsRegressor()))\n",
    "    modelos.append((\"SVM\", LinearSVR()))\n",
    "    modelos.append((\"Árvore de Decisão\", DecisionTreeRegressor()))\n",
    "    modelos.append((\"Random Forest\", RandomForestRegressor()))\n",
    "    modelos.append((\"Extra Tree\", ExtraTreesRegressor()))\n",
    "    modelos.append((\"Bagging\", BaggingRegressor()))\n",
    "    modelos.append((\"AdaBoost\", AdaBoostRegressor()))\n",
    "    modelos.append((\"Voting\", VotingRegressor(estimators=[(\"AD\",DecisionTreeRegressor()),(\"GB\", GradientBoostingRegressor()),(\"RL\", LinearRegression())])))\n",
    "    modelos.append((\"Gradient Tree Boosting\", GradientBoostingRegressor()))\n",
    "    modelos.append((\"XGBoost\", XGBRegressor()))    \n",
    "\n",
    "    # Criando um Dataframe para armazenar a média de cada um dos algoritmos testados.\n",
    "    dfMedias   = pd.DataFrame(columns = ['Algoritmo', 'Media'])\n",
    "\n",
    "    # Define a quantidade de folds\n",
    "    numeroFolds = 5\n",
    "\n",
    "    # Define a semente para criar os folds\n",
    "    seed = 28\n",
    "\n",
    "    # KFold divide o conjunto de dados em grupos de amostras, chamados folds\n",
    "    kfold = KFold(n_splits = numeroFolds, shuffle=True, random_state = seed)\n",
    "\n",
    "    for nome, construtor in modelos:\n",
    "        # Cross Validation\n",
    "        resultados = cross_val_score(construtor, dadosEntrada, dadosSaida, cv=kfold, scoring=\"r2\")\n",
    "\n",
    "        # Calcula a média dos resultados\n",
    "        media = resultados.mean()*100\n",
    "\n",
    "        # Define os parâmetros para adicionar a linha no dataframe\n",
    "        novaLinha = {\"Algoritmo\": nome,\n",
    "                     \"Media\": media}\n",
    "\n",
    "        # Adicionando uma linha no final do DataFrame\n",
    "        dfMedias.loc[len(dfMedias.index)] = novaLinha\n",
    "\n",
    "    # Ordena o dataframe da maior média para a menor    \n",
    "    dfMedias.sort_values(by=[\"Media\"], ascending=False, inplace=True)\n",
    "    \n",
    "    return dfMedias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 - Cross Validation com dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 - Cross Validation com dados normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria o objeto da classe MinMaxScaler \n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de entrada\n",
    "xNormalizado = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(xNormalizado, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 - Cross Validation com dados padronizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto StandardScaler, calcula a média e o desvio-padrão que serão usados para padronizar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de entrada\n",
    "xPadronizado = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(xPadronizado, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Preparando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 - Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria o objeto da classe MinMaxScaler \n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de  Xtreino\n",
    "XtreinoNormalizados = min_max_scaler.fit_transform(Xtreino)\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de Xteste\n",
    "XtesteNormalizados = min_max_scaler.fit_transform(Xteste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 - Padronizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria o objeto StandardScaler, calcula a média e o desvio-padrão que serão usados para padronizar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de Xtreino\n",
    "XtreinoPadronizados = scaler.fit_transform(Xtreino)\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de Xteste\n",
    "XtestePadronizados = scaler.fit_transform(Xteste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 - Selecionando a apresentação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os dados podem estar com apresentação \"Originais\", \"Normalizados\" ou \"Padronizados\"\n",
    "apresentacaoDosDados = \"Originais\"\n",
    "\n",
    "if apresentacaoDosDados == \"Originais\":\n",
    "    dadosXtreino = Xtreino\n",
    "    dadosXteste = Xteste\n",
    "elif apresentacaoDosDados == \"Normalizados\":\n",
    "    dadosXtreino = XtreinoNormalizados\n",
    "    dadosXteste = XtesteNormalizados\n",
    "else:\n",
    "    dadosXtreino = XtreinoPadronizados\n",
    "    dadosXteste = XtestePadronizados\n",
    "\n",
    "print(\"Os dados estão com a seguinte apresentação:\", apresentacaoDosDados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Criando os modelos de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame para comparar a acurácia de cada algoritmo\n",
    "# DataFrame para comparar a R2 de cada algoritmo\n",
    "comparaAlgoritmo = {\"Algoritmo\": [\"Gradient Tree Boosting\", \"XGBRegressor\", \"Extra Trees Regressor\"],\n",
    "                   \"R2\": [\"-\", \"-\", \"-\"],\n",
    "                   \"Erro Absoluto Medio\": [\"-\", \"-\", \"-\"]\n",
    "                   }\n",
    "dfComparaAlgoritmo = pd.DataFrame(comparaAlgoritmo)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.11 - Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisando os melhores parâmetros com RandomizedSearchCV\n",
    "# Cria um dicionário com os valores que serão testados como parâmetro\n",
    "parametros = {\n",
    "   \"n_estimators\": [100, 110, 150],\n",
    "   \"learning_rate\": [0.1, 0.5, 1.0, 1.5],\n",
    "}\n",
    "\n",
    "# Cria o modelo que desejamos testar os melhores parâmetros\n",
    "gradientBoostingRegressor= GradientBoostingRegressor()\n",
    "\n",
    "# Cria o objeto do tipo RandomizedSearchCV\n",
    "randomizedSearch = RandomizedSearchCV(estimator = gradientBoostingRegressor, param_distributions = parametros, random_state = 11)\n",
    "\n",
    "# Treinando os parâmetros. ATENÇÃO: Deve-se usar todo conjunto de dados.\n",
    "randomizedSearch.fit(X, y)\n",
    "\n",
    "# Salvando os melhores parâmetros em uma lista\n",
    "melhoresParametros = []\n",
    "for k in randomizedSearch.best_params_:\n",
    "    melhoresParametros.append(randomizedSearch.best_params_[k])\n",
    "\n",
    "# Print do resultado\n",
    "print(\"R2 médio: %.3f\" % (randomizedSearch.best_score_ * 100) + \"%\")\n",
    "print(\"Melhores parâmetros para o modelo:\", randomizedSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "gradientBoostingRegressor = GradientBoostingRegressor(n_estimators = melhoresParametros[0],\n",
    "                                   learning_rate=melhoresParametros[1], random_state=1\n",
    "                                   )\n",
    "\n",
    "# Treinamento do modelo\n",
    "gradientBoostingRegressor.fit(dadosXtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = gradientBoostingRegressor.predict(dadosXteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Erro Absoluto Médio\n",
    "mae = mean_absolute_error(Yteste, previsoes)\n",
    "print(\"Erro absoluto médio: %.2f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[0,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[0,2] =  round(mae,2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.12 - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisando os melhores parâmetros com RandomizedSearchCV\n",
    "# Cria um dicionário com os valores que serão testados como parâmetro\n",
    "parametros = {\n",
    "   \"colsample_bynode\": [0.1, 0.3, 0.5, 0.8, 1],\n",
    "   \"learning_rate\": [0.1, 0.15, 0.5, 1.0, 1.5],\n",
    "   \"max_depth\": [2, 4, 5, 6, 8],\n",
    "   \"num_parallel_tree\": [5, 10, 15, 20, 25],\n",
    "   \"subsample\": [0.1, 0.3, 0.5, 0.8, 1]\n",
    "}\n",
    "\n",
    "# Cria o modelo que desejamos testar os melhores parâmetros\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Cria o objeto do tipo RandomizedSearchCV\n",
    "randomizedSearch = RandomizedSearchCV(estimator = xgb, param_distributions = parametros, random_state = 11)\n",
    "\n",
    "# Treinando os parâmetros. ATENÇÃO: Deve-se usar todo conjunto de dados.\n",
    "randomizedSearch.fit(X, y)\n",
    "\n",
    "# Salvando os melhores parâmetros em uma lista\n",
    "melhoresParametros = []\n",
    "for k in randomizedSearch.best_params_:\n",
    "    melhoresParametros.append(randomizedSearch.best_params_[k])\n",
    "\n",
    "# Print do resultado\n",
    "print(\"R2 médio: %.3f\" % (randomizedSearch.best_score_ * 100) + \"%\")\n",
    "print(\"Melhores parâmetros para o modelo:\", randomizedSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "xgb = XGBRegressor(booster='gbtree',\n",
    "                   subsample= melhoresParametros[0],\n",
    "                   num_parallel_tree= melhoresParametros[1],\n",
    "                   max_depth= melhoresParametros[2],\n",
    "                   learning_rate= melhoresParametros[3],\n",
    "                   colsample_bynode= melhoresParametros[4],\n",
    "                   tree_method= 'gpu_hist',\n",
    "                   nthread=16\n",
    "                   )\n",
    "\n",
    "# Criar o modelo com o código abaixo, caso o computador não tenha placa de vídeo dedicada com suporte a CUDA\n",
    "# xgb = XGBRegressor()\n",
    "\n",
    "# Treinamento do modelo\n",
    "xgb.fit(dadosXtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = xgb.predict(dadosXteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Erro Absoluto Médio\n",
    "mae = mean_absolute_error(Yteste, previsoes)\n",
    "print(\"Erro absoluto médio: %.2f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[1,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[1,2] =  round(mae, 2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 - Extra Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisando os melhores parâmetros com RandomizedSearchCV\n",
    "# Cria um dicionário com os valores que serão testados como parâmetro\n",
    "parametros = {\n",
    "    \"n_estimators\": [100, 150, 250, 300],\n",
    "    \"criterion\": ['squared_error', 'absolute_error'], \n",
    "    \"max_depth\": [100, 150, 200, 350],\n",
    "    \"min_samples_split\": [2, 3, 4, 5] \n",
    "}\n",
    "\n",
    "# Cria o modelo que desejamos testar os melhores parâmetros\n",
    "extraTreesRegressor = ExtraTreesRegressor(random_state=81)\n",
    "\n",
    "# Cria o objeto do tipo RandomizedSearchCV\n",
    "randomizedSearch = RandomizedSearchCV(estimator = extraTreesRegressor, param_distributions = parametros, random_state = 11)\n",
    "\n",
    "# Treinando os parâmetros. ATENÇÃO: Deve-se usar todo conjunto de dados.\n",
    "randomizedSearch.fit(X, y)\n",
    "\n",
    "# Salvando os melhores parâmetros em uma lista\n",
    "melhoresParametros = []\n",
    "for k in randomizedSearch.best_params_:\n",
    "    melhoresParametros.append(randomizedSearch.best_params_[k])\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Avaliação média do R2: %.3f\" % (randomizedSearch.best_score_ * 100) + \"%\")\n",
    "print(\"Melhores parâmetros para o modelo:\", randomizedSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando os melhores parâmetros segundo o RandomizedSearchCV\n",
    "# Criando o modelo\n",
    "extraTreesRegressor = ExtraTreesRegressor(n_estimators = melhoresParametros[0], \n",
    "                                          min_samples_split = melhoresParametros[1], \n",
    "                                          max_depth = melhoresParametros[2],\n",
    "                                          criterion = melhoresParametros[3],\n",
    "                                          random_state=26\n",
    "                                         )\n",
    "\n",
    "# Treinamento do modelo\n",
    "extraTreesRegressor.fit(Xtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = extraTreesRegressor.predict(Xteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Erro Absoluto Médio\n",
    "mae = mean_absolute_error(Yteste, previsoes)\n",
    "print(\"Erro absoluto médio: %.2f\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[2,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[2,2] =  round(mae, 2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - Selecionando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena o DataFrame de acordo o valor do Erro Absoluto Medio, em ordem crecente\n",
    "dfComparaAlgoritmo.sort_values(by=[\"Erro Absoluto Medio\"], inplace=True)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o modelo final\n",
    "modeloFinal = xgb\n",
    "modeloFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 - Salvando e carregando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 - Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo\n",
    "arquivo = 'Dados/Boston-Housing/modeloRegressorFinal.sav'\n",
    "pickle.dump(modeloFinal, open(arquivo, 'wb'))\n",
    "print(\"Modelo salvo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 - Carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo\n",
    "modeloRegressor = pickle.load(open(arquivo, 'rb'))\n",
    "print(\"Modelo carregado!\")\n",
    "modeloRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 - Salvando o objeto de normalização/padronização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os dados podem estar com apresentação \"Originais\", \"Normalizados\" ou \"Padronizados\"\n",
    "if apresentacaoDosDados == \"Normalizados\":\n",
    "    arquivoNormalizador = 'Dados/Boston-Housing/normalizador.sav'\n",
    "    pickle.dump(min_max_scaler, open(arquivoNormalizador, 'wb'))\n",
    "    print(\"Normalizador salvo!\")\n",
    "elif apresentacaoDosDados == \"Padronizados\":\n",
    "    arquivoPadronizador = 'Dados/Boston-Housing/padronizador.sav'\n",
    "    pickle.dump(scaler, open(arquivoPadronizador, 'wb'))\n",
    "    print(\"Padronizador salvo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 - Validando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o dataframe\n",
    "dfValidacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz as previsões dos novos dados\n",
    "\n",
    "if apresentacaoDosDados == \"Originais\":\n",
    "    novosDados = dfValidacao[df.columns[0:13]].values\n",
    "    # Fazendo previsões\n",
    "    previsoes = modeloRegressor.predict(novosDados)\n",
    "\n",
    "elif apresentacaoDosDados == \"Normalizados\":\n",
    "    # Carregando o objeto de normalização dos dados\n",
    "    normalizador = pickle.load(open(arquivoNormalizador, 'rb'))\n",
    "    # Normalizando os novos dados\n",
    "    novosDados = dfValidacao[df.columns[0:13]].values\n",
    "    novosDadosNormalizados = normalizador.transform(novosDados)\n",
    "    previsoes = modeloRegressor.predict(novosDadosNormalizados)\n",
    "\n",
    "else:\n",
    "    # Carregando o objeto de padronização dos dados\n",
    "    padronizador = pickle.load(open(arquivoPadronizador, 'rb'))\n",
    "    # Padronizando os novos dados\n",
    "    novosDados = dfValidacao[df.columns[0:13]].values\n",
    "    novosDadosPadronizados = padronizador.transform(novosDados)\n",
    "    # Fazendo previsões\n",
    "    previsoes = modeloRegressor.predict(novosDadosPadronizados)\n",
    "\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
