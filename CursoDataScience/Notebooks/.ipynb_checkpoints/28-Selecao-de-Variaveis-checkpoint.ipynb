{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Seleção de variáveis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os pacotes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando os dados\n",
    "df = pd.read_csv('Dados/Auto-mpg/mtcars.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(df)\n",
    "numeroColunas = 10\n",
    "X = df[[\"cyl\",\"disp\",\"hp\",\"drat\",\"wt\",\"qsec\",\"vs\",\"am\",\"gear\",\"carb\"]].values.reshape((numeroObservacoes, numeroColunas)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = df['mpg'].values # y pode ser um vetor\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = RandomForestRegressor()\n",
    "\n",
    "# Treinamento do modelo\n",
    "modelo.fit(X, y)\n",
    "\n",
    "# Extraindo a importância\n",
    "importancia = modelo.feature_importances_\n",
    "importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico com a importância das variáveis\n",
    "variaveis = [\"cyl\",\"disp\",\"hp\",\"drat\",\"wt\",\"qsec\",\"vs\",\"am\",\"gear\",\"carb\"]\n",
    "plt.bar(variaveis, importancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(df)\n",
    "numeroColunas = 10\n",
    "X = df[[\"cyl\",\"disp\",\"hp\",\"drat\",\"wt\",\"qsec\",\"vs\",\"am\",\"gear\",\"carb\"]].values.reshape((numeroObservacoes, numeroColunas)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = df['mpg'].values # y pode ser um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide os dados em treino e teste\n",
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.   ,  75.7  ,  52.   ,   4.93 ,   1.615,  18.52 ,   1.   ,\n",
       "          1.   ,   4.   ,   2.   ],\n",
       "       [  8.   , 318.   , 150.   ,   2.76 ,   3.52 ,  16.87 ,   0.   ,\n",
       "          0.   ,   3.   ,   2.   ],\n",
       "       [  6.   , 167.6  , 123.   ,   3.92 ,   3.44 ,  18.9  ,   1.   ,\n",
       "          0.   ,   4.   ,   4.   ],\n",
       "       [  8.   , 440.   , 230.   ,   3.23 ,   5.345,  17.42 ,   0.   ,\n",
       "          0.   ,   3.   ,   4.   ],\n",
       "       [  8.   , 350.   , 245.   ,   3.73 ,   3.84 ,  15.41 ,   0.   ,\n",
       "          0.   ,   3.   ,   4.   ],\n",
       "       [  8.   , 360.   , 175.   ,   3.15 ,   3.44 ,  17.02 ,   0.   ,\n",
       "          0.   ,   3.   ,   2.   ],\n",
       "       [  4.   , 120.3  ,  91.   ,   4.43 ,   2.14 ,  16.7  ,   0.   ,\n",
       "          1.   ,   5.   ,   2.   ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xteste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Criando o modelo\n",
    "modelo1 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo1.fit(Xtreino, Ytreino)\n",
    "\n",
    "# Fazendo previsões\n",
    "previsoes1 = modelo1.predict(Xteste)\n",
    "\n",
    "# Resultado\n",
    "r2 = r2_score(Yteste, previsoes1)\n",
    "print(\"O R2 do modelo é:\", r2*100)\n",
    "\n",
    "# Cáculo do erro\n",
    "print(\"O erro do modelo é:\", mean_squared_error(previsoes1, Yteste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(df)\n",
    "numeroColunas = 10\n",
    "X = df[[\"cyl\",\"disp\",\"hp\",\"wt\"]].values.reshape((numeroObservacoes, numeroColunas)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = df['mpg'].values # y pode ser um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide os dados em treino e teste\n",
    "# random_state garante que o dataset seja dividido sempre com os mesmos dados\n",
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.   ,  75.7  ,  52.   ,   4.93 ,   1.615,  18.52 ,   1.   ,\n",
       "          1.   ,   4.   ,   2.   ],\n",
       "       [  8.   , 318.   , 150.   ,   2.76 ,   3.52 ,  16.87 ,   0.   ,\n",
       "          0.   ,   3.   ,   2.   ],\n",
       "       [  6.   , 167.6  , 123.   ,   3.92 ,   3.44 ,  18.9  ,   1.   ,\n",
       "          0.   ,   4.   ,   4.   ],\n",
       "       [  8.   , 440.   , 230.   ,   3.23 ,   5.345,  17.42 ,   0.   ,\n",
       "          0.   ,   3.   ,   4.   ],\n",
       "       [  8.   , 350.   , 245.   ,   3.73 ,   3.84 ,  15.41 ,   0.   ,\n",
       "          0.   ,   3.   ,   4.   ],\n",
       "       [  8.   , 360.   , 175.   ,   3.15 ,   3.44 ,  17.02 ,   0.   ,\n",
       "          0.   ,   3.   ,   2.   ],\n",
       "       [  4.   , 120.3  ,  91.   ,   4.43 ,   2.14 ,  16.7  ,   0.   ,\n",
       "          1.   ,   5.   ,   2.   ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xteste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "modelo2 = RandomForestRegressor()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo2.fit(Xtreino, Ytreino)\n",
    "\n",
    "# Fazendo previsões\n",
    "previsoes2 = modelo2.predict(Xteste)\n",
    "\n",
    "# Resultado\n",
    "r2 = r2_score(Yteste, previsoes2)\n",
    "print(\"O R2 do modelo é:\", r2*100)\n",
    "\n",
    "# Cáculo do erro\n",
    "print(\"O erro do modelo é:\", mean_squared_error(previsoes2, Yteste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminação Recursiva de Atributos - Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(df)\n",
    "numeroColunas = 10\n",
    "X = df[[\"cyl\",\"disp\",\"hp\",\"drat\",\"wt\",\"qsec\",\"vs\",\"am\",\"gear\",\"carb\"]].values.reshape((numeroObservacoes, numeroColunas)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = df['mpg'].values # y pode ser um vetor\n",
    "\n",
    "# Criando o modelo\n",
    "modelo3 = ExtraTreesRegressor()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo3.fit(X, y)\n",
    "\n",
    "# Criando Eliminação Recursiva de Atributos RFE\n",
    "eliminacaoRecursiva = RFE(modelo3)\n",
    "\n",
    "# Treinando Eliminação Recursiva de Atributos RFE\n",
    "eliminacaoRecursivaTreinada = eliminacaoRecursiva.fit(X, y)\n",
    "\n",
    "print(\"Variáveis Selecionadas: %s\" % eliminacaoRecursivaTreinada.support_)\n",
    "print(\"Ranking das variáveis: %s\" % eliminacaoRecursivaTreinada.ranking_)\n",
    "print(\"Número de Melhores variáveis: %d\" % eliminacaoRecursivaTreinada.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(variaveis, eliminacaoRecursivaTreinada.support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(df)\n",
    "numeroColunas = 10\n",
    "X = df[[\"cyl\",\"disp\",\"hp\",\"drat\",\"wt\",\"qsec\",\"vs\",\"am\",\"gear\",\"carb\"]].values.reshape((numeroObservacoes, numeroColunas)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = df['mpg'].values # y pode ser um vetor\n",
    "\n",
    "# Cria o objeto SelectKBest\n",
    "selectkBest = SelectKBest(score_func = f_regression, k=4)\n",
    "\n",
    "# Executa a função em (X, y) e obtém as variáveis selecionadas\n",
    "selectkBestTreinado = selectkBest.fit(X, y)\n",
    "\n",
    "# Reduz X para as variáveis selecionadas\n",
    "variaveisSelecionadas = selectkBestTreinado.transform(X)\n",
    "\n",
    "# Resultados\n",
    "print('\\nRanking:', selectkBestTreinado.scores_)\n",
    "print('\\nVariáveis Selecionadas: \\n\\n', variaveisSelecionadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(variaveis, selectkBestTreinado.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
