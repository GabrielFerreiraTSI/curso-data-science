{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Airfoil Self-Noise Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.8.5\n",
      "Pandas Version: 1.5.1\n",
      "Matplotlib Version: 3.5.3\n",
      "Sklearn Version: 1.1.2\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Python Version:', python_version())\n",
    "\n",
    "# Verificando as versões dos pacotes instalados\n",
    "pandasVersion = !pip show pandas\n",
    "matplotlibVersion = !pip show matplotlib\n",
    "sklearnVersion = !pip show scikit-learn\n",
    "print('Pandas', pandasVersion[1])\n",
    "print(\"Matplotlib\", matplotlibVersion[1])\n",
    "print(\"Sklearn\", sklearnVersion[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Definição do Problema de Negócio\n",
    "<details>\n",
    "    <summary>\n",
    "        <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>&nbsp;&nbsp;Clique para mais detalhes</a>\n",
    "    </summary>\n",
    "    <br>\n",
    "\n",
    "Este conjunto de dados da NASA foi obtido a partir de uma série de testes aerodinâmicos e acústicos de seções bi e tridimensionais de pás de aerofólio conduzidas em um túnel de vento. <br>\n",
    "Os dados são de aerofólios NACA 0012 de tamanhos diferentes que foram submetidos a diferentes velocidades de túnel de vento e ângulos de ataque. A envergadura do aerofólio e a posição do observador foram as mesmas em todos os experimentos. <br>\n",
    "O objetivo deste trabalho é prever o nível de pressão sonora medida em decibéis a partir das variáveis existentes.<br><br>\n",
    "Descrição das variáveis: <br>\n",
    "- **Frequency**: Frequência medida em Hertzs;<br>\n",
    "- **Angle of attack**: Ângulo de ataque do vento medido em graus; <br>\n",
    "- **Chord length**: Comprimento do acorde medido em metros; <br>\n",
    "- **Free-stream velocity**: Velocidade de fluxo livre em metros por segundo;<br>\n",
    "- **Suction side displacement thickness**: Espessura de deslocamento do lado de sucção em metros;<br>\n",
    "- **Scaled sound pressure level**: Nível escalado de pressão sonora em decibéis (variável alvo).<br>\n",
    "    \n",
    "Endereço do conjunto de dados: https://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Coletando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 - Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação e exploração do conjunto de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cálculos matemáticos\n",
    "import math\n",
    "\n",
    "# Plotagem de gráficos\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imputação de valores nulos\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Converter variáveis categóricas em números\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Seleção de variáveis\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Dividir dados de treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Buscar os melhores parâmetros que serão utilizados nos modelos preditivos\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Algoritmos de Regressão\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor, AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Métricas de avaliação dos modelos preditivos\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Carregar e salvar objetos Python em arquivos no disco\n",
    "import pickle\n",
    "\n",
    "# Esse módulo ignara os avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 - Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo nome para as colunas\n",
    "colunas = [\"Frequencia\", \"Angulo_ataque\", \"Comprimento_acorde\", \"Velocidade_fluxo\", \"Espessura_deslocamento\", \"Nivel_pressao_sonora\"]\n",
    "\n",
    "# Endereço para download\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\"\n",
    "\n",
    "# Carregando os dados\n",
    "df = pd.read_csv(url, sep = \"\\t\", names = colunas)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando a variável alvo\n",
    "variavelAlvo = \"Nivel_pressao_sonora\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Reservar linhas para validar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma amostra do conjuto de dados\n",
    "# O parâmetro \"n\" define a quantidade de linhas da amostra\n",
    "dfValidacao = df.sample(n=2, random_state=1)\n",
    "dfValidacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo do DataFrame original as linhas que serão utilizadas para validar o modelo \n",
    "for k in dfValidacao.index:\n",
    "    df.drop([k], inplace = True)\n",
    "\n",
    "# É importante reiniciar os índices após a exclusão de linhas\n",
    "df.reset_index(inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo coluna\n",
    "df.drop([\"index\"], axis=1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Explorando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 - Informações sobre o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando informações sobre o dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Tratando valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores nulos por coluna\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto do tipo SimpleImputer com a média como estratégia  \n",
    "imputeMedia = SimpleImputer(missing_values=np.nan, strategy= \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o objeto do tipo SimpleImputer, substitui os valores nulos pela média em cada coluna com valor NA\n",
    "for k in df.columns[0:22]:\n",
    "    \n",
    "    # Verifica se a coluna possui valores nulos e se os valores não são do tipo texto\n",
    "    if df[k].isnull().sum() > 0 and df[k].dtype != object:\n",
    "        \n",
    "        # Realiza a imputação nos dados nulos\n",
    "        df[k] = imputeMedia.fit_transform(df[k].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Tratando dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem dados duplicados.\n",
    "# Ocorrem dados duplicados quando uma linha inteira, é igual a outra\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo as linhas duplicadas mantendo a primeira ocorrência da linha\n",
    "df.drop_duplicates(ignore_index=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 - Tratando valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a quantidade de valores únicos\n",
    "# Variáveis quantitativas com muitos valores únicos podem prejudicar o aprendizado de máquina\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 - Análise descritiva dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1 - Parâmetros dos gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a paleta de cores\n",
    "sns.color_palette(\"pastel\")\n",
    "\n",
    "# Define o tema utilizado.\n",
    "sns.set_theme(style=\"darkgrid\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2 - Funções para desenhar os gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### a) Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um histograma\n",
    "def desenhaHistograma(coluna, variavelAnalisada):\n",
    "\n",
    "    # Calculando a quantidade de classes da variável analisada\n",
    "    n = coluna.count()\n",
    "    k = round(1+3.3*math.log10(n))\n",
    "   \n",
    "    # Calculando o intervalo de cada classe\n",
    "    frequencias, intervalos = np.histogram(coluna, bins = k)\n",
    "\n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.histplot(coluna, bins=k, kde=True)\n",
    "    ax.set_title(\"Histograma da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.set_xlabel(variavelAnalisada, fontsize = 12)\n",
    "    ax.set_ylabel(\"Frequência\", fontsize = 12)\n",
    "    ax.set_xticks(intervalos) \n",
    "    ax.bar_label(ax.containers[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b) Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um Boxplot\n",
    "def desenhaBoxplot(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.boxplot(data=coluna)\n",
    "    ax.set_title(\"Boxplot da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.set_xticklabels([variavelAnalisada]) # exibe o nome da variável\n",
    "    larguraBox = 0.63\n",
    "    i=0\n",
    "\n",
    "    # calcula o primeiro quartil (q1), o segundo (q2) e o terceiro quartil (q3)\n",
    "    q1, q2, q3 = coluna.quantile(0.25), coluna.quantile(0.5), coluna.quantile(0.75)\n",
    "    \n",
    "    # Lista com os quartis\n",
    "    quartis = [q1, q2, q3]\n",
    "\n",
    "    # Exibe os quartis no gráfico\n",
    "    for q in quartis:\n",
    "        x = i-larguraBox/2\n",
    "        y = q\n",
    "        ax.annotate('%.2f' % q, (x,y),\n",
    "                    xytext=(x-0.1, y), textcoords='data',\n",
    "                    va='center', ha='right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### c) Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um Scatter Plot\n",
    "def desenhaScatterPlot(colunaX, colunaY, variavelAnalisadaX, variavelAnalisadaY):\n",
    "    \n",
    "    # Cria o gráfico definido pelos valores do eixo x e do eixo y respectivamente.\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.scatterplot(x=colunaX, y=colunaY) \n",
    "    ax.set_title(\"Relação da variável \" + variavelAnalisadaX + \" com a variável \" + variavelAnalisadaY, fontsize = 16)\n",
    "    ax.set_xlabel(variavelAnalisadaX, fontsize = 12)\n",
    "    ax.set_ylabel(variavelAnalisadaY, fontsize = 12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### d) Gráfico de Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um gráfico de pizza\n",
    "def desenhaPizza(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Calculando o percentual\n",
    "    percentuais = round((coluna.value_counts()/coluna.value_counts().sum())*100, 2)\n",
    "\n",
    "    # Nome das categorias\n",
    "    nomeDasCategorias = coluna.value_counts().index\n",
    "\n",
    "    # Desenhando o gráfico\n",
    "    fig, ax = plt.subplots(figsize=(13, 6))\n",
    "    ax.pie(percentuais, labels=nomeDasCategorias, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    ax.set_title(\"Percentuais da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.legend(title=variavelAnalisada,loc=\"center left\",bbox_to_anchor=(1., 0., 0.5, 1.))\n",
    "    ax.axis('equal') # Garante que o gráfico seja desenhado no formato de círculo.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### d) Countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar um gráfico Countplot\n",
    "def desenhaCountPlot(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Desenhando o gráfico\n",
    "    fig = plt.subplots(figsize=(13, 6))\n",
    "    ax = sns.countplot(x=coluna, palette=(\"Pastel1\"), order = coluna.value_counts().index)\n",
    "    ax.set_title(\"Frequência absoluta da variável \" + variavelAnalisada, fontsize = 16)\n",
    "    ax.bar_label(ax.containers[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### e) Função para verificar Assimetria e Curtose de uma variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica a assimetria e a curtose de uma variável\n",
    "def verificaAssimetriaCurtose(coluna, variavelAnalisada):\n",
    "    \n",
    "    # Verificando a assimetria da coluna\n",
    "    coeficienteAssimetria = coluna.skew()\n",
    "\n",
    "    if coeficienteAssimetria == 0:\n",
    "        print(\"\\n- A distribuição dos dados é simétrica, ou seja, a cauda à direita e à esquerda são iguais, visto que, o coeficiente de assimetria da variável \" + variavelAnalisada + \" é:\\n\", coeficienteAssimetria)\n",
    "    elif coeficienteAssimetria < 0:\n",
    "        print(\"\\n- A distribuição dos dados é assimétrica negativa, ou seja, a cauda é maior à esquerda, visto que, o coeficiente de assimetria da variável \" + variavelAnalisada + \" é:\\n\", coeficienteAssimetria)\n",
    "    else:\n",
    "        print(\"\\n- A distribuição dos dados é assimétrica positiva, ou seja, a cauda é maior à direita, visto que, o coeficiente de assimetria da variável \" + variavelAnalisada + \" é:\\n\", coeficienteAssimetria)\n",
    "        \n",
    "    # Verificando a curtose da coluna\n",
    "    coeficienteCurtose = coluna.kurtosis()\n",
    "\n",
    "    if coeficienteCurtose == 0:\n",
    "        print(\"\\n- A curva apresenta uma distribuição normal, ou seja, mesocúrtica, visto que, o coeficiente de curtose da variável \" + variavelAnalisada + \" é:\\n\", coeficienteCurtose)\n",
    "    elif coeficienteCurtose < 0:\n",
    "        print(\"\\n- A curva é muito achatada, ou seja, platicúrtica, visto que, o coeficiente de curtose da variável \" + variavelAnalisada + \" é:\\n\", coeficienteCurtose)\n",
    "    else:\n",
    "        print(\"\\n- A curva é muito alongada, ou seja, leptocúrtica, visto que, o coeficiente de curtose da variável \" + variavelAnalisada + \" é:\\n\", coeficienteCurtose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.3 Análise descritiva das variáveis quantitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5012\\1203487899.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Loop que percorre todas as colunas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Verifica se a coluna não possui valores do tipo texto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "for k in df.columns[0:len(df.columns)-1]:\n",
    "    # Verifica se a coluna não possui valores do tipo texto\n",
    "    if df[k].dtypes != object:\n",
    "        \n",
    "        # Sumário estatístico\n",
    "        print(\"Resumo estatístico da variável \" + k + \"\\n\", df[k].describe())\n",
    "        \n",
    "        # Verifica a assimetria e a curtose da variável\n",
    "        verificaAssimetriaCurtose(df[k], k)\n",
    "        \n",
    "        # Histograma\n",
    "        desenhaHistograma(df[k], k)\n",
    "        \n",
    "        # Boxplot\n",
    "        desenhaBoxplot(df[k], k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.4 Análise descritiva das variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "for k in df.columns[0:len(df.columns)-1]:\n",
    "    # Verifica se a coluna possui valores do tipo texto\n",
    "    if df[k].dtypes == object:\n",
    "        \n",
    "        # Frequência absoluta \n",
    "        desenhaCountPlot(df[k], k)\n",
    "        \n",
    "        # Percentuais\n",
    "        desenhaPizza(df[k], k)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.4.1 Análise descritiva da variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário estatístico\n",
    "pd.DataFrame(df[variavelAlvo].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assimetria e curtose da variável alvo\n",
    "verificaAssimetriaCurtose(df[variavelAlvo], variavelAlvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequência absoluta \n",
    "desenhaHistograma(df[variavelAlvo], variavelAlvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentuais\n",
    "desenhaBoxplot(df[variavelAlvo], variavelAlvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.5 - Correlação entre as variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.5.1 - Matriz de correlação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a correlação \n",
    "correlacao = df.corr()\n",
    "\n",
    "# Criando uma máscara\n",
    "mascara = np.zeros_like(correlacao)\n",
    "\n",
    "# Selecionando a matriz triangular inferior da máscara.\n",
    "mascara[np.triu_indices_from(mascara)] = True\n",
    "\n",
    "# Cria a matriz de correlação\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "sns.heatmap(data = correlacao,\n",
    "            mask = mascara,\n",
    "            annot = True,\n",
    "            fmt = '.2f',\n",
    "            cmap='Blues',\n",
    "\n",
    "            )\n",
    "plt.title('Matriz de correlação', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.5.2 - Correlação entre a variável Frequencia e a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScatterPlot\n",
    "desenhaScatterPlot(df.Frequencia, df[variavelAlvo], \"Frequencia\", variavelAlvo )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.5.3 - Correlação entre a variável Angulo_ataque e a variável Espessura_deslocamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScatterPlot\n",
    "desenhaScatterPlot(df.Angulo_ataque, df.Espessura_deslocamento, \"Angulo_ataque\", \"Espessura_deslocamento\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Transformando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz uma cópia do dataframe\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tratando valores iguais a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as colunas que possuem valores iguais a zero\n",
    "# Loop que percorre todas as colunas\n",
    "# A notação de slicing [0:13] é para não incluir a variável alvo, porque apesar de ter números, a variável alvo é categórica\n",
    "for k in df2.columns[0:13]:\n",
    "    \n",
    "    # Verifica se os valores não são do tipo texto\n",
    "    if df2[k].dtype != object:\n",
    "        \n",
    "        # Imprime na tela a quantidade de valores iguais a zero existentes na coluna\n",
    "        print(k + \":\", len(df2[df2[k] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Identificando e tratando valores outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop que percorre todas as colunas\n",
    "# A notação de slicing [0:13] é para não incluir a variável alvo, porque apesar de ter números, a variável alvo é categórica\n",
    "for k in df.columns[0:13]:\n",
    "    \n",
    "    # Verifica se os valores da coluna não são do tipo texto\n",
    "    if df2[k].dtype != object:\n",
    "       \n",
    "        # Calculando o zscore da coluna\n",
    "        zscore = (df2[k] - df2[k].mean()) / df2[k].std()\n",
    "        \n",
    "        # Pesquisando valores menores que -3 ou maiores que 3 que são considerados outliers\n",
    "        outliers = zscore[(zscore < -3) | (zscore > 3)]\n",
    "        \n",
    "        # Calculando o limite superior\n",
    "        limiteSuperior = df2[k].mean() + 3 * df2[k].std()\n",
    "\n",
    "        # Calculando o limite inferior\n",
    "        limiteInferior = df2[k].mean() - 3 * df2[k].std()\n",
    "        \n",
    "        # Verifica se há outliers na coluna \n",
    "        if len(outliers) > 0:\n",
    "            \n",
    "            # Calcula a média da coluna, excluindo os valores outliers\n",
    "            media = df2[k][(df[k] > limiteInferior) & (df2[k] <= limiteSuperior)].mean()\n",
    "            \n",
    "            # Cria uma lista vazia para armazenar as linhas com outliers\n",
    "            linhasComOutlier = []\n",
    "             \n",
    "            # Loop que percorre as linhas com outliers\n",
    "            for j in outliers.index:\n",
    "                \n",
    "                # Substitui a célula com valor outlier pela média\n",
    "                df2[k] = df2[k].replace(df2.iloc[j][k], media)\n",
    "                \n",
    "                # Adiciona o índice da linha na lista\n",
    "                linhasComOutlier.append(j)\n",
    "                \n",
    "            print(\"- Quantidade de valores outliers \" + \"da variável \" + k + \" substituídos pela média\"  + \":\", len(outliers))\n",
    "            print(\"- Linha (as) da variável \" + k + \" que foi (foram) alterada (as):\", linhasComOutlier)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Convertendo variáveis categóricas em números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o tipo de dados das colunas\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Convertendo as variáveis preditoras de texto para número"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2.1 Encoding com o Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.get_dummies(df2)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o nome das colunas\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizando o dataframe\n",
    "valoresVariavelAlvo = df3[variavelAlvo]\n",
    "df3.drop([variavelAlvo],  axis=1, inplace = True)\n",
    "\n",
    "# Atualizando a variável alvo\n",
    "df3[variavelAlvo] = valoresVariavelAlvo\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Dividindo os dados em treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATENÇÃO!! Qual o dataframe será utilizado df2 ou df3 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo uma cópia do dataframa\n",
    "dfDados = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(dfDados)\n",
    "numeroVariaveisPreditoras = len(dfDados.columns)-1\n",
    "\n",
    "# A notação de slicing [0:numeroVariaveisPreditoras] é para não incluir a variável alvo\n",
    "X = dfDados[dfDados.columns[0:numeroVariaveisPreditoras]].values.reshape((numeroObservacoes, numeroVariaveisPreditoras)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = dfDados[variavelAlvo].values # y pode ser um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisa os melhores valores para o parâmetro random_state\n",
    "# Array de valores para random_state de 1 até 200\n",
    "arrayRandomStates = np.arange(start=1, stop=200)\n",
    "\n",
    "# Cria uma lista vazia para armazenar os acertos\n",
    "listaR2 = []\n",
    "\n",
    "# Loop que percorre todos os valores da arrayRandomStates\n",
    "for k in arrayRandomStates:\n",
    "    Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=k)\n",
    "    modelo = XGBRegressor()\n",
    "    modelo.fit(Xtreino, Ytreino)\n",
    "    previsoes = modelo.predict(Xteste)\n",
    "    listaR2.append(round(r2_score(Yteste, previsoes)*100,2))\n",
    "    \n",
    "# Exibe os melhores valores para o random_state\n",
    "resultados = pd.DataFrame({'random_state':arrayRandomStates, \n",
    "                           'R2':listaR2})\n",
    "melhorRandomState = resultados[resultados['R2'] == resultados['R2'].max()]\n",
    "melhorRandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide os dados em treino e teste\n",
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=int(melhorRandomState[\"random_state\"][0:1].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Seleção de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um objeto da classe SFS para selecionar as melhores variáveis preditoras conforme R2, utilizando o algoritmo XGBRegressor.\n",
    "sfs = SFS (\n",
    "    estimator  = XGBRegressor(), \n",
    "    k_features = numeroVariaveisPreditoras,\n",
    "    forward    = True, \n",
    "    floating   = False, \n",
    "    scoring    = 'r2',\n",
    "    cv         = 3\n",
    ")\n",
    "\n",
    "# Convertendo os valores de X para DataFrame. Isso facilita para retornar o nome das variáveis\n",
    "dfX = pd.DataFrame(X, columns=dfDados.columns[0:numeroVariaveisPreditoras])\n",
    "\n",
    "# Convertendo os valores de y para um objeto do tipo Series do Pandas\n",
    "y_series = pd.Series(y)\n",
    "\n",
    "# Pesquisando as melhores variáveis preditoras.\n",
    "sfs = sfs.fit(\n",
    "    X = dfDados[dfDados.columns[0:numeroVariaveisPreditoras]], \n",
    "    y = dfDados[variavelAlvo], \n",
    ")\n",
    "\n",
    "# Convertendo o resultado da pesquisa das melhores variáveis para um dataframe.\n",
    "# O método \"T\" transforma linhas em colunas e colunas em linhas\n",
    "dfSelecaoVariaveis = pd.DataFrame(sfs.subsets_).T\n",
    "\n",
    "# Converte a coluna \"avg_score\" para o tipo float\n",
    "dfSelecaoVariaveis.avg_score = dfSelecaoVariaveis.avg_score.astype(float)\n",
    "\n",
    "# Ordena o dataframe de acordo a variável \"avg_score\" do maior para o menor\n",
    "dfSelecaoVariaveis.sort_values(by=[\"avg_score\"], ascending=False, inplace=True)\n",
    "dfSelecaoVariaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolhendo as melhores variáveis\n",
    "melhoresVariaveis = dfSelecaoVariaveis.iloc[0,3]\n",
    "\n",
    "# Convertendo a Tupla para uma lista\n",
    "variaveisSelecionadas = list(melhoresVariaveis)\n",
    "variaveisSelecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Dividindo os dados de treino e teste com as variáveis selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as variáveis preditoras e a variável alvo\n",
    "numeroObservacoes = len(dfDados)\n",
    "numeroVariaveisPreditoras = len(variaveisSelecionadas)\n",
    "X = dfDados[variaveisSelecionadas].values.reshape((numeroObservacoes, numeroVariaveisPreditoras)) # X deve sempre ser uma matriz e nunca um vetor\n",
    "y = dfDados[variavelAlvo].values # y pode ser um vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisa os melhores valores para o parâmetro random_state\n",
    "# Array de valores para random_state de 1 até 100\n",
    "arrayRandomStates = np.arange(start=1, stop=200)\n",
    "\n",
    "# Cria uma lista vazia para armazenar os acertos\n",
    "listaR2 = []\n",
    "\n",
    "# Loop que percorre todos os valores da arrayRandomStates\n",
    "for k in arrayRandomStates:\n",
    "    Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=k)\n",
    "    modelo = XGBRegressor()\n",
    "    modelo.fit(Xtreino, Ytreino)\n",
    "    previsoes = modelo.predict(Xteste)\n",
    "    listaR2.append(round(r2_score(Yteste, previsoes)*100,2))\n",
    "    \n",
    "# Exibe os melhores valores para o random_state\n",
    "resultados = pd.DataFrame({'random_state':arrayRandomStates, \n",
    "                           'R2':listaR2})\n",
    "melhorRandomState = resultados[resultados['R2'] == resultados['R2'].max()]\n",
    "melhorRandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide os dados em treino e teste\n",
    "Xtreino, Xteste, Ytreino, Yteste = train_test_split(X, y, test_size = 0.2, random_state=int(melhorRandomState[\"random_state\"][0:1].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculaCrossValidation(dadosEntrada, dadosSaida):\n",
    "    # Criando uma lista vazia para armazenar os modelos de Machine Learning\n",
    "    modelos = []\n",
    "    \n",
    "    # Adicionando os modelos a lista\n",
    "    modelos.append((\"Regressão Linear\", LinearRegression()))\n",
    "    modelos.append((\"Ridge\", Ridge()))\n",
    "    modelos.append((\"KNN\", KNeighborsRegressor()))\n",
    "    modelos.append((\"SVM\", LinearSVR()))\n",
    "    modelos.append((\"Árvore de Decisão\", DecisionTreeRegressor()))\n",
    "    modelos.append((\"Random Forest\", RandomForestRegressor()))\n",
    "    modelos.append((\"Extra Tree\", ExtraTreesRegressor()))\n",
    "    modelos.append((\"Bagging\", BaggingRegressor()))\n",
    "    modelos.append((\"AdaBoost\", AdaBoostRegressor()))\n",
    "    modelos.append((\"Voting\", VotingRegressor(estimators=[(\"AD\",DecisionTreeRegressor()),(\"GB\", GradientBoostingRegressor()),(\"RL\", LinearRegression())])))\n",
    "    modelos.append((\"Gradient Tree Boosting\", GradientBoostingRegressor()))\n",
    "    modelos.append((\"XGBoost\", XGBRegressor()))    \n",
    "\n",
    "    # Criando um Dataframe para armazenar a média de cada um dos algoritmos testados.\n",
    "    dfMedias   = pd.DataFrame(columns = ['Algoritmo', 'Media'])\n",
    "\n",
    "    # Define a quantidade de folds\n",
    "    numeroFolds = 5\n",
    "\n",
    "    # Define a semente para criar os folds\n",
    "    seed = 28\n",
    "\n",
    "    # KFold divide o conjunto de dados em grupos de amostras, chamados folds\n",
    "    kfold = KFold(n_splits = numeroFolds, shuffle=True, random_state = seed)\n",
    "\n",
    "    for nome, construtor in modelos:\n",
    "        # Cross Validation\n",
    "        resultados = cross_val_score(construtor, dadosEntrada, dadosSaida, cv=kfold, scoring=\"r2\")\n",
    "\n",
    "        # Calcula a média dos resultados\n",
    "        media = resultados.mean()*100\n",
    "\n",
    "        # Define os parâmetros para adicionar a linha no dataframe\n",
    "        novaLinha = {\"Algoritmo\": nome,\n",
    "                     \"Media\": media}\n",
    "\n",
    "        # Adicionando uma linha no final do DataFrame\n",
    "        dfMedias.loc[len(dfMedias.index)] = novaLinha\n",
    "\n",
    "    # Ordena o dataframe da maior média para a menor    \n",
    "    dfMedias.sort_values(by=[\"Media\"], ascending=False, inplace=True)\n",
    "    \n",
    "    return dfMedias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 - Cross Validation com dados originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 - Cross Validation com dados normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto da classe MinMaxScaler \n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de entrada\n",
    "xNormalizado = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(xNormalizado, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 - Cross Validation com dados padronizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto StandardScaler, calcula a média e o desvio-padrão que serão usados para padronizar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de entrada\n",
    "xPadronizado = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula cross validation\n",
    "calculaCrossValidation(xPadronizado, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Preparando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 - Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto da classe MinMaxScaler \n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de  Xtreino\n",
    "XtreinoNormalizados = min_max_scaler.fit_transform(Xtreino)\n",
    "\n",
    "# Realiza a normalização dimensionando as variáveis em uma escala entre 0 e 1 nos dados de Xteste\n",
    "XtesteNormalizados = min_max_scaler.fit_transform(Xteste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 - Padronizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto StandardScaler, calcula a média e o desvio-padrão que serão usados para padronizar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de Xtreino\n",
    "XtreinoPadronizados = scaler.fit_transform(Xtreino)\n",
    "\n",
    "# Realiza a padronização centralizando e dimensionando dados nos dados de Xteste\n",
    "XtestePadronizados = scaler.fit_transform(Xteste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 - Selecionando a apresentação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os dados podem estar com apresentação \"Originais\", \"Normalizados\" ou \"Padronizados\"\n",
    "apresentacaoDosDados = \"Originais\"\n",
    "\n",
    "if apresentacaoDosDados == \"Originais\":\n",
    "    dadosXtreino = Xtreino\n",
    "    dadosXteste = Xteste\n",
    "elif apresentacaoDosDados == \"Normalizados\":\n",
    "    dadosXtreino = XtreinoNormalizados\n",
    "    dadosXteste = XtesteNormalizados\n",
    "else:\n",
    "    dadosXtreino = XtreinoPadronizados\n",
    "    dadosXteste = XtestePadronizados\n",
    "\n",
    "print(\"Os dados estão com a seguinte apresentação:\", apresentacaoDosDados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Criando os modelos de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame para comparar a acurácia de cada algoritmo\n",
    "# DataFrame para comparar a R2 de cada algoritmo\n",
    "comparaAlgoritmo = {\"Algoritmo\": [\"Extra Tree\", \"XGBRegressor\", \"Random Forest\"],\n",
    "                   \"R2\": [\"-\", \"-\", \"-\"],\n",
    "                   \"Erro Absoluto Medio\": [\"-\", \"-\", \"-\"],\n",
    "                   \"Erro Quadratico Medio\": [\"-\", \"-\", \"-\"],\n",
    "                   \"Raiz quadrada do Erro Quadratico Medio\": [\"-\", \"-\", \"-\"] \n",
    "                   }\n",
    "dfComparaAlgoritmo = pd.DataFrame(comparaAlgoritmo)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.11 - Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "extraTreesRegressor = ExtraTreesRegressor()\n",
    "\n",
    "# Treinamento do modelo\n",
    "extraTreesRegressor.fit(dadosXtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = extraTreesRegressor.predict(dadosXteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Erro Absoluto Médio\n",
    "mae = mean_absolute_error(Yteste, previsoes)\n",
    "print(\"Erro absoluto médio: %.2f\" % mae)\n",
    "\n",
    "# Calcula o Erro Quadrático Médio\n",
    "mse = mean_squared_error(Yteste, previsoes)\n",
    "print(\"Erro Quadrático Médio: %.2f\" % mse)\n",
    "\n",
    "# Calcula a Raiz quadrada do Erro Quadrático Médio\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Raiz quadrada do Erro Quadrático Médio: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[0,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[0,2] =  round(mae,2)\n",
    "dfComparaAlgoritmo.iloc[0,3] =  round(mse,2)\n",
    "dfComparaAlgoritmo.iloc[0,4] =  round(rmse,2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliando os resíduos\n",
    "Uma importante premissa em problemas de regressão é que os resíduos, ou seja, as diferenças entre o valores reais e o valores previstos, devem seguir uma distribuição normal, ou pelo menos, de forma aproximada. <br> \n",
    "Em uma distribuição normal, a curva do gráfico de densidade possui um formato de sino e é simétrica em torno da média, e quanto menor o desvio-padrão, mais concentrada é a curva em torno da média. Em uma distribuição normal a média é igual a 0 e o desvio-padrão é igual a 1.<br>\n",
    "Quando os resíduos do modelo apresentam uma distribuição normal significa que o modelo apresentou um bom desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando os residuos\n",
    "residuos = Yteste - previsoes\n",
    "\n",
    "# Criando um distplot\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "ax = sns.distplot(residuos)\n",
    "plt.show()\n",
    "\n",
    "# Visualizando a média e o desvio padrão dos resíduos\n",
    "print(\"Média dos resíduos:\", residuos.mean())\n",
    "print(\"Desvio padrão dos resíduos:\", residuos.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 11.12 - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Treinamento do modelo\n",
    "xgb.fit(dadosXtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = xgb.predict(dadosXteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Erro Absoluto Médio\n",
    "mae = mean_absolute_error(Yteste, previsoes)\n",
    "print(\"Erro absoluto médio: %.2f\" % mae)\n",
    "\n",
    "# Calcula o Erro Quadrático Médio\n",
    "mse = mean_squared_error(Yteste, previsoes)\n",
    "print(\"Erro Quadrático Médio: %.2f\" % mse)\n",
    "\n",
    "# Calcula a Raiz quadrada do Erro Quadrático Médio\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Raiz quadrada do Erro Quadrático Médio: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[1,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[1,2] =  round(mae, 2)\n",
    "dfComparaAlgoritmo.iloc[1,3] =  round(mse,2)\n",
    "dfComparaAlgoritmo.iloc[1,4] =  round(rmse,2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando os residuos\n",
    "residuos = Yteste - previsoes\n",
    "\n",
    "# Criando um distplot\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "ax = sns.distplot(residuos)\n",
    "plt.show()\n",
    "\n",
    "# Visualizando a média e o desvio padrão dos resíduos\n",
    "print(\"Média dos resíduos:\", residuos.mean())\n",
    "print(\"Desvio padrão dos resíduos:\", residuos.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando os melhores parâmetros segundo o RandomizedSearchCV\n",
    "# Criando o modelo\n",
    "randomForestRegressor = RandomForestRegressor(random_state=6)\n",
    "\n",
    "# Treinamento do modelo\n",
    "randomForestRegressor.fit(Xtreino, Ytreino)\n",
    "\n",
    "# Previsões com os dados de teste\n",
    "previsoes = randomForestRegressor.predict(Xteste)\n",
    "\n",
    "# Calculando o R2 do modelo\n",
    "r2 = r2_score(Yteste, previsoes)\n",
    "print(\"R2 do modelo: %.2f\" % (r2*100) + \"%\")\n",
    "\n",
    "# Calcula o Erro Absoluto Médio\n",
    "mae = mean_absolute_error(Yteste, previsoes)\n",
    "print(\"Erro absoluto médio: %.2f\" % mae)\n",
    "\n",
    "# Calcula o Erro Quadrático Médio\n",
    "mse = mean_squared_error(Yteste, previsoes)\n",
    "print(\"Erro Quadrático Médio: %.2f\" % mse)\n",
    "\n",
    "# Calcula a Raiz quadrada do Erro Quadrático Médio\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Raiz quadrada do Erro Quadrático Médio: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando o dataframe com o desempenho dos algoritmos\n",
    "dfComparaAlgoritmo.iloc[2,1] =  round((r2 * 100), 2)\n",
    "dfComparaAlgoritmo.iloc[2,2] =  round(mae, 2)\n",
    "dfComparaAlgoritmo.iloc[2,3] =  round(mse,2)\n",
    "dfComparaAlgoritmo.iloc[2,4] =  round(rmse,2)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando os residuos\n",
    "residuos = Yteste - previsoes\n",
    "\n",
    "# Criando um distplot\n",
    "fig = plt.subplots(figsize=(13, 6))\n",
    "ax = sns.distplot(residuos)\n",
    "plt.show()\n",
    "\n",
    "# Visualizando a média e o desvio padrão dos resíduos\n",
    "print(\"Média dos resíduos:\", residuos.mean())\n",
    "print(\"Desvio padrão dos resíduos:\", residuos.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - Selecionando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena o DataFrame de acordo o valor do Erro Absoluto Medio, em ordem crecente\n",
    "dfComparaAlgoritmo.sort_values(by=[\"Erro Absoluto Medio\"], inplace=True)\n",
    "dfComparaAlgoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o modelo final\n",
    "modeloFinal = xgb\n",
    "modeloFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 - Salvando e carregando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 - Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo\n",
    "arquivo = 'Dados/Airfoil-Self-Noise-Dataset/modeloRegressorFinal.sav'\n",
    "pickle.dump(modeloFinal, open(arquivo, 'wb'))\n",
    "print(\"Modelo salvo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 - Carregando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo\n",
    "modeloRegressor = pickle.load(open(arquivo, 'rb'))\n",
    "print(\"Modelo carregado!\")\n",
    "modeloRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 - Salvando o objeto de normalização/padronização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os dados podem estar com apresentação \"Originais\", \"Normalizados\" ou \"Padronizados\"\n",
    "if apresentacaoDosDados == \"Normalizados\":\n",
    "    arquivoNormalizador = 'Dados/Airfoil-Self-Noise-Dataset/normalizador.sav'\n",
    "    pickle.dump(min_max_scaler, open(arquivoNormalizador, 'wb'))\n",
    "    print(\"Normalizador salvo!\")\n",
    "elif apresentacaoDosDados == \"Padronizados\":\n",
    "    arquivoPadronizador = 'Dados/Airfoil-Self-Noise-Dataset/padronizador.sav'\n",
    "    pickle.dump(scaler, open(arquivoPadronizador, 'wb'))\n",
    "    print(\"Padronizador salvo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 - Validando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o dataframe\n",
    "dfValidacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz as previsões dos novos dados\n",
    "\n",
    "if apresentacaoDosDados == \"Originais\":\n",
    "    novosDados = dfValidacao[variaveisSelecionadas].values\n",
    "    # Fazendo previsões\n",
    "    previsoes = modeloRegressor.predict(novosDados)\n",
    "\n",
    "elif apresentacaoDosDados == \"Normalizados\":\n",
    "    # Carregando o objeto de normalização dos dados\n",
    "    normalizador = pickle.load(open(arquivoNormalizador, 'rb'))\n",
    "    # Normalizando os novos dados\n",
    "    novosDados = dfValidacao[variaveisSelecionadas].values\n",
    "    novosDadosNormalizados = normalizador.transform(novosDados)\n",
    "    previsoes = modeloRegressor.predict(novosDadosNormalizados)\n",
    "\n",
    "else:\n",
    "    # Carregando o objeto de padronização dos dados\n",
    "    padronizador = pickle.load(open(arquivoPadronizador, 'rb'))\n",
    "    # Padronizando os novos dados\n",
    "    novosDados = dfValidacao[variaveisSelecionadas].values\n",
    "    novosDadosPadronizados = padronizador.transform(novosDados)\n",
    "    # Fazendo previsões\n",
    "    previsoes = modeloRegressor.predict(novosDadosPadronizados)\n",
    "\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
